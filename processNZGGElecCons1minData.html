<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Ben Anderson (b.anderson@soton.ac.uk, @dataknut)" />


<title>Processing, cleaning and saving NZ GREEN Grid project 1 minute electricity power data</title>

<script src="processNZGGElecCons1minData_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="processNZGGElecCons1minData_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="processNZGGElecCons1minData_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="processNZGGElecCons1minData_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="processNZGGElecCons1minData_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="processNZGGElecCons1minData_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="processNZGGElecCons1minData_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="processNZGGElecCons1minData_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="processNZGGElecCons1minData_files/navigation-1.1/tabsets.js"></script>
<script src="processNZGGElecCons1minData_files/navigation-1.1/codefolding.js"></script>
<link href="processNZGGElecCons1minData_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="processNZGGElecCons1minData_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Processing, cleaning and saving NZ GREEN Grid project 1 minute electricity power data</h1>
<h4 class="author"><em>Ben Anderson (<a href="mailto:b.anderson@soton.ac.uk">b.anderson@soton.ac.uk</a>, <code>@dataknut</code>)</em></h4>
<h4 class="date"><em>Last run at: 2018-05-09 09:51:18</em></h4>

</div>



<div id="citation" class="section level1">
<h1><span class="header-section-number">1</span> Citation</h1>
<p>If you wish to use any of the material from this report please cite as:</p>
<ul>
<li>Anderson, B. (2018) Processing, cleaning and saving NZ GREEN Grid project 1 minute electricity power data, University of Otago: Dunedin, NZ.</li>
</ul>

</div>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">2</span> Introduction</h1>
<p>Report circulation:</p>
<ul>
<li>Restricted to: <a href="https://www.otago.ac.nz/centre-sustainability/research/energy/otago050285.html">NZ GREEn Grid</a> project partners and contractors.</li>
</ul>
<div id="purpose" class="section level2">
<h2><span class="header-section-number">2.1</span> Purpose</h2>
<p>This report is intended to:</p>
<ul>
<li>load and clean the project electricity power data (Grid Spy)</li>
<li>save the cleaned data out as a single file per household</li>
<li>produce summary data quality statistics</li>
</ul>
</div>
<div id="requirements" class="section level2">
<h2><span class="header-section-number">2.2</span> Requirements:</h2>
<ul>
<li>grid spy 1 minute data downloads</li>
</ul>
</div>
<div id="history" class="section level2">
<h2><span class="header-section-number">2.3</span> History</h2>
<p>Generally tracked via our git.soton <a href="https://git.soton.ac.uk/ba1e12/nzGREENGrid">repo</a>:</p>
<ul>
<li><a href="https://git.soton.ac.uk/ba1e12/nzGREENGrid/commits/master">history</a></li>
<li><a href="https://git.soton.ac.uk/ba1e12/nzGREENGrid/issues">issues</a></li>
</ul>
</div>
<div id="support" class="section level2">
<h2><span class="header-section-number">2.4</span> Support</h2>
<p>This work was supported by:</p>
<ul>
<li>The <a href="https://www.otago.ac.nz/">University of Otago</a></li>
<li>The New Zealand <a href="http://www.mbie.govt.nz/">Ministry of Business, Innovation and Employment (MBIE)</a></li>
<li><a href="http://www.energy.soton.ac.uk/tag/spatialec/">SPATIALEC</a> - a <a href="http://ec.europa.eu/research/mariecurieactions/about-msca/actions/if/index_en.htm">Marie Skłodowska-Curie Global Fellowship</a> based at the University of Otago’s <a href="http://www.otago.ac.nz/centre-sustainability/staff/otago673896.html">Centre for Sustainability</a> (2017-2019) &amp; the University of Southampton’s Sustainable Energy Research Group (2019-202).</li>
</ul>
<p>This work is (c) 2018 the University of Southampton.</p>
<p>We do not ‘support’ the code but if you have a problem check the <a href="https://git.soton.ac.uk/ba1e12/nzGREENGrid/issues">issues</a> on our <a href="https://git.soton.ac.uk/ba1e12/nzGREENGrid">repo</a> and if it doesn’t already exist, open one. We might be able to fix it :-)</p>
</div>
</div>
<div id="obtain-listing-of-files" class="section level1">
<h1><span class="header-section-number">3</span> Obtain listing of files</h1>
<p>In this section we generate a listing of all 1 minute data files that we have received. If we are running over the complete dataset then we will be using data from:</p>
<ul>
<li>/hum-csafe/Research Projects/GREEN Grid/_RAW DATA/GridSpyData/</li>
</ul>
<p>In this run we are using data from:</p>
<ul>
<li>~/Data/NZGreenGrid/gridspy/1min_orig/</li>
</ul>
<p>If these do not match then this may be a test run.</p>
<pre class="r"><code>print(paste0(&quot;Looking for 1 minute data using pattern = &quot;, pattern1Min, &quot; in &quot;, fpath, &quot; - could take a while...&quot;))</code></pre>
<pre><code>## [1] &quot;Looking for 1 minute data using pattern = *at1.csv$ in ~/Data/NZGreenGrid/gridspy/1min_orig/ - could take a while...&quot;</code></pre>
<pre class="r"><code>system.time(fListCompleteDT &lt;- data.table::as.data.table(list.files(path = fpath, pattern = pattern1Min, # use the default pattern to filter e.g. 1m from 30s files
                                            recursive = TRUE)))</code></pre>
<pre><code>##    user  system elapsed 
##   0.006   0.008   0.018</code></pre>
<pre class="r"><code>nFiles &lt;- nrow(fListCompleteDT)
print(paste0(&quot;Found &quot;, tidyNum(nFiles), &quot; files&quot;))</code></pre>
<pre><code>## [1] &quot;Found 958 files&quot;</code></pre>
<pre class="r"><code>if(nrow(fListCompleteDT) == 0){
  stop(paste0(&quot;No matching data files found, please check your path (&quot;, fpath, &quot;) or your search pattern (&quot;, pattern1Min, &quot;)&quot;))
} else {
  print(paste0(&quot;Processing file list and getting file meta-data (please be patient)&quot;))
  fListCompleteDT &lt;- fListCompleteDT[, c(&quot;hhID&quot;,&quot;fileName&quot;) := data.table::tstrsplit(V1, &quot;/&quot;)]
  fListCompleteDT &lt;- fListCompleteDT[, fullPath := paste0(fpath, hhID,&quot;/&quot;,fileName)]
  loopCount &lt;- 1
  # now loop over the files and collect metadata
  for(f in fListCompleteDT[,fullPath]){
    rf &lt;- path.expand(f) # just in case of ~ etc
    fsize &lt;- file.size(rf)
    fmtime &lt;- lubridate::ymd_hms(file.mtime(rf), tz = &quot;Pacific/Auckland&quot;) # requires lubridate
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, fSize := fsize]
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, fMTime := fmtime]
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, fMDate := as.Date(fmtime)]
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, dateColName := paste0(&quot;unknown - file not loaded (fsize = &quot;, fsize, &quot;)&quot;)]
    # only try to read files where we think there might be data
    loadThis &lt;- ifelse(fsize &gt; dataThreshold, &quot;Loading (fsize &gt; threshold)&quot;, &quot;Skipping (fsize &lt; threshold)&quot;)
    if(fullFb){print(paste0(&quot;Checking file &quot;, loopCount, &quot; of &quot;, nFiles ,
                            &quot; (&quot;, round(100*(loopCount/nFiles),2), &quot;% checked): &quot;, loadThis))}
    if(fsize &gt; dataThreshold){
      if(fullFb){print(paste0(&quot;fSize (&quot;, fsize, &quot;) &gt; threshold (&quot;, dataThreshold, &quot;) -&gt; loading &quot;, f))}
      row1DT &lt;- fread(f, nrows = 1)
      # what is the date column called?
      fListCompleteDT &lt;- fListCompleteDT[fullPath == f, dateColName := &quot;unknown - can&#39;t tell&quot;]
      if(nrow(dplyr::select(row1DT, dplyr::contains(&quot;NZ&quot;))) &gt; 0){ # requires dplyr
        setnames(row1DT, &#39;date NZ&#39;, &quot;dateTime_char&quot;)
        row1DT &lt;- row1DT[, dateColName := &quot;date NZ&quot;]
        fListCompleteDT &lt;- fListCompleteDT[fullPath == f, dateColName := &quot;date NZ&quot;]
      } 
      if(nrow(dplyr::select(row1DT, dplyr::contains(&quot;UTC&quot;))) &gt; 0){ # requires dplyr
        setnames(row1DT, &#39;date UTC&#39;, &quot;dateTime_char&quot;)
        row1DT &lt;- row1DT[, dateColName := &quot;date UTC&quot;]
        fListCompleteDT &lt;- fListCompleteDT[fullPath == f, dateColName := &quot;date UTC&quot;]
      }
      # split dateTime
      row1DT &lt;- row1DT[, c(&quot;date_char&quot;, &quot;time_char&quot;) := data.table::tstrsplit(dateTime_char, &quot; &quot;)]
      # add example of date to metadata - presumably they are the same in each file?!
      fListCompleteDT &lt;- fListCompleteDT[fullPath == f, dateExample := row1DT[1, date_char]]
      
      if(fullFb){print(paste0(&quot;Checking date formats in &quot;, f))}
      dt &lt;- gs_checkDates(row1DT)
      fListCompleteDT &lt;- fListCompleteDT[fullPath == f, dateFormat := dt[1, dateFormat]]
      fListCompleteDT &lt;- fListCompleteDT[fullPath == f, dateFormat := dt[1, dateFormat]]
      if(fullFb){print(paste0(&quot;Done &quot;, f))}
    }
    loopCount &lt;- loopCount + 1
  }
  print(&quot;All files checked&quot;)
  
  # any date formats are still ambiguous need a deeper inspection using the full file - could be slow
  fAmbig &lt;- fListCompleteDT[dateFormat == &quot;ambiguous&quot;, fullPath]
  
  for(fa in fAmbig){
    if(baTest | fullFb){print(paste0(&quot;Checking ambiguous date formats in &quot;, fa))}
    ambDT &lt;- fread(fa)
    if(nrow(dplyr::select(ambDT, dplyr::contains(&quot;NZ&quot;))) &gt; 0){ # requires dplyr
      setnames(ambDT, &#39;date NZ&#39;, &quot;dateTime_char&quot;)
    } 
    if(nrow(dplyr::select(ambDT, dplyr::contains(&quot;UTC&quot;))) &gt; 0){ # requires dplyr
      setnames(ambDT, &#39;date UTC&#39;, &quot;dateTime_char&quot;)
    }
    ambDT &lt;- ambDT[, c(&quot;date_char&quot;, &quot;time_char&quot;) := data.table::tstrsplit(dateTime_char, &quot; &quot;)]
    ambDT &lt;- gs_checkDates(ambDT)
    # set what we now know (or guess!)
    fListCompleteDT &lt;- fListCompleteDT[fullPath == fa, dateFormat := ambDT[1,dateFormat]]
  }
      
  ofile &lt;- paste0(outPath, fListInterim)
  print(paste0(&quot;Saving 1 minute data files interim metadata to &quot;, ofile))
  write.csv(fListCompleteDT, ofile)
  print(&quot;Done&quot;)
}</code></pre>
<pre><code>## [1] &quot;Processing file list and getting file meta-data (please be patient)&quot;
## [1] &quot;All files checked&quot;
## [1] &quot;Checking ambiguous date formats in ~/Data/NZGreenGrid/gridspy/1min_orig/rf_46/12Oct2016-20Nov2017at1.csv&quot;
## [1] &quot;Saving 1 minute data files interim metadata to ~/Data/NZGreenGrid/gridspy/consolidated/1min/fListCompleteDT_interim.csv&quot;
## [1] &quot;Done&quot;</code></pre>
<pre class="r"><code>print(paste0(&quot;Overall we have &quot;, nrow(fListCompleteDT), &quot; files from &quot;, uniqueN(fListCompleteDT$hhID), &quot; households.&quot;))</code></pre>
<pre><code>## [1] &quot;Overall we have 958 files from 2 households.&quot;</code></pre>
<pre class="r"><code># for use below
nFiles &lt;- nrow(fListCompleteDT)
nFilesNotLoaded &lt;- nrow(fListCompleteDT[dateColName %like% &quot;unknown&quot;])</code></pre>
<p>Overall we have 958 files from 2 households. Of the 958, 544 (56.78%) were <em>not</em> loaded/checked as their file sizes indicated that they contained no data.</p>
<p>We now need to check how many of the loaded files have an ambiguous or default date - these could introduce errors.</p>
<pre class="r"><code># short cut if file list already saved ----
#ifile &lt;- paste0(outPath, fListInterim)
#print(paste0(&quot;Loading 1 minute data files interim metadata to &quot;, ifile))
#fListCompleteDT &lt;- fread(ifile)
  
  
t &lt;- fListCompleteDT[, .(nFiles = .N), keyby = .(dateColName, dateFormat)]

knitr::kable(caption = &quot;Number of files with given date column names by inferred date format&quot;, t)</code></pre>
<table>
<caption>Number of files with given date column names by inferred date format</caption>
<thead>
<tr class="header">
<th align="left">dateColName</th>
<th align="left">dateFormat</th>
<th align="right">nFiles</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">date NZ</td>
<td align="left">dmy - definite</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">date NZ</td>
<td align="left">mdy - definite</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">date NZ</td>
<td align="left">ymd - default (but day/month value &lt;= 12)</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">date NZ</td>
<td align="left">ymd - definite</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">date UTC</td>
<td align="left">ambiguous</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">date UTC</td>
<td align="left">ymd - default (but day/month value &lt;= 12)</td>
<td align="right">161</td>
</tr>
<tr class="odd">
<td align="left">date UTC</td>
<td align="left">ymd - definite</td>
<td align="right">247</td>
</tr>
<tr class="even">
<td align="left">unknown - file not loaded (fsize = 2751)</td>
<td align="left">NA</td>
<td align="right">302</td>
</tr>
<tr class="odd">
<td align="left">unknown - file not loaded (fsize = 43)</td>
<td align="left">NA</td>
<td align="right">242</td>
</tr>
</tbody>
</table>
<p>Results to note:</p>
<ul>
<li>There are 1 ambiguous files</li>
<li>The non-loaded files only have 2 distinct file sizes, confirming that they are unlikely to contain useful data.</li>
</ul>
<p>We now inspect the ambiguous and (some of) the default files.</p>
<p>To help with data cleaning the following table lists files that are ambiguous.</p>
<pre class="r"><code># list ambigious files
aList &lt;- fListCompleteDT[dateFormat == &quot;ambiguous&quot;, .(file = V1, dateColName, dateExample, dateFormat)]

knitr::kable(caption = &quot;Files with ambigious date formats&quot;, aList)</code></pre>
<table>
<caption>Files with ambigious date formats</caption>
<thead>
<tr class="header">
<th align="left">file</th>
<th align="left">dateColName</th>
<th align="left">dateExample</th>
<th align="left">dateFormat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">rf_46/12Oct2016-20Nov2017at1.csv</td>
<td align="left">date UTC</td>
<td align="left">11-10-16</td>
<td align="left">ambiguous</td>
</tr>
</tbody>
</table>
<p>Looking at the file names we will assume they are dmy.</p>
<pre class="r"><code>fListCompleteDT &lt;- fListCompleteDT[dateFormat == &quot;ambiguous&quot;, dateFormat := &quot;dmy - inferred&quot;]</code></pre>
<p>The following table lists ‘date NZ’ files which are set by default only - do they look OK to assume dateFormat?</p>
<pre class="r"><code># list default files
aList &lt;- fListCompleteDT[dateColName == &quot;date NZ&quot; &amp; dateFormat %like% &quot;default&quot;, .(file = V1, fSize, dateColName, dateExample, dateFormat)]

knitr::kable(caption = &quot;Files with inferred default date formats&quot;, head(aList))</code></pre>
<table>
<caption>Files with inferred default date formats</caption>
<thead>
<tr class="header">
<th align="left">file</th>
<th align="right">fSize</th>
<th align="left">dateColName</th>
<th align="left">dateExample</th>
<th align="left">dateFormat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">rf_01/1Jan2014-24May2014at1.csv</td>
<td align="right">6255737</td>
<td align="left">date NZ</td>
<td align="left">2014-01-06</td>
<td align="left">ymd - default (but day/month value &lt;= 12)</td>
</tr>
</tbody>
</table>
<p>These look OK if we compare the file names with the dateExample.</p>
<p>The following table lists ‘date NZ’ files which are set by default only - do they look OK to assume dateFormat?</p>
<pre class="r"><code># list default files
aList &lt;- fListCompleteDT[dateColName == &quot;date UTC&quot; &amp; dateFormat %like% &quot;default&quot;, .(file = V1, fSize, dateColName, dateExample, dateFormat)]

knitr::kable(caption = &quot;Files with inferred default date formats&quot;, head(aList))</code></pre>
<table>
<caption>Files with inferred default date formats</caption>
<thead>
<tr class="header">
<th align="left">file</th>
<th align="right">fSize</th>
<th align="left">dateColName</th>
<th align="left">dateExample</th>
<th align="left">dateFormat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">rf_46/10Apr2017-11Apr2017at1.csv</td>
<td align="right">292721</td>
<td align="left">date UTC</td>
<td align="left">2017-04-09</td>
<td align="left">ymd - default (but day/month value &lt;= 12)</td>
</tr>
<tr class="even">
<td align="left">rf_46/10Aug2017-11Aug2017at1.csv</td>
<td align="right">292888</td>
<td align="left">date UTC</td>
<td align="left">2017-08-09</td>
<td align="left">ymd - default (but day/month value &lt;= 12)</td>
</tr>
<tr class="odd">
<td align="left">rf_46/10Dec2017-11Dec2017at1.csv</td>
<td align="right">292823</td>
<td align="left">date UTC</td>
<td align="left">2017-12-09</td>
<td align="left">ymd - default (but day/month value &lt;= 12)</td>
</tr>
<tr class="even">
<td align="left">rf_46/10Feb2017-11Feb2017at1.csv</td>
<td align="right">286736</td>
<td align="left">date UTC</td>
<td align="left">2017-02-09</td>
<td align="left">ymd - default (but day/month value &lt;= 12)</td>
</tr>
<tr class="odd">
<td align="left">rf_46/10Feb2018-11Feb2018at1.csv</td>
<td align="right">299084</td>
<td align="left">date UTC</td>
<td align="left">2018-02-09</td>
<td align="left">ymd - default (but day/month value &lt;= 12)</td>
</tr>
<tr class="even">
<td align="left">rf_46/10Jan2017-11Jan2017at1.csv</td>
<td align="right">297659</td>
<td align="left">date UTC</td>
<td align="left">2017-01-09</td>
<td align="left">ymd - default (but day/month value &lt;= 12)</td>
</tr>
</tbody>
</table>
<p>These also look OK so we will stick with the following derived date formats:</p>
<pre class="r"><code>t &lt;- fListCompleteDT[, .(nFiles = .N), keyby = .(dateColName, dateFormat)]

knitr::kable(caption = &quot;Number of files with given date column names by final imputed date format&quot;, t)</code></pre>
<table>
<caption>Number of files with given date column names by final imputed date format</caption>
<thead>
<tr class="header">
<th align="left">dateColName</th>
<th align="left">dateFormat</th>
<th align="right">nFiles</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">date NZ</td>
<td align="left">dmy - definite</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">date NZ</td>
<td align="left">mdy - definite</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">date NZ</td>
<td align="left">ymd - default (but day/month value &lt;= 12)</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">date NZ</td>
<td align="left">ymd - definite</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">date UTC</td>
<td align="left">dmy - inferred</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">date UTC</td>
<td align="left">ymd - default (but day/month value &lt;= 12)</td>
<td align="right">161</td>
</tr>
<tr class="odd">
<td align="left">date UTC</td>
<td align="left">ymd - definite</td>
<td align="right">247</td>
</tr>
<tr class="even">
<td align="left">unknown - file not loaded (fsize = 2751)</td>
<td align="left">NA</td>
<td align="right">302</td>
</tr>
<tr class="odd">
<td align="left">unknown - file not loaded (fsize = 43)</td>
<td align="left">NA</td>
<td align="right">242</td>
</tr>
</tbody>
</table>
<div id="data-file-quality-checks" class="section level2">
<h2><span class="header-section-number">3.1</span> Data file quality checks</h2>
<p>The following chart shows the distribution of these files over time using their sizes. Note that white indicates the presence of small files which may not contain observations.</p>
<pre class="r"><code>myCaption &lt;- paste0(&quot;Data source: &quot;, fpath,
                    &quot;\nUsing data received up to &quot;, Sys.Date())

plotDT &lt;- fListCompleteDT[, .(nFiles = .N,
                              meanfSize = mean(fSize)), 
                          keyby = .(hhID, date = as.Date(fMDate))]

ggplot2::ggplot(plotDT, aes( x = date, y = hhID, fill = log(meanfSize))) +
  geom_tile() +
  scale_fill_gradient(low = &quot;white&quot;, high = &quot;black&quot;) + 
  scale_x_date(date_labels = &quot;%Y %b&quot;, date_breaks = &quot;1 month&quot;) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) + 
  labs(title = &quot;Mean file size of all grid spy data files received per day&quot;,
       caption = paste0(myCaption, 
                        &quot;\nLog file size used as some files are full year data&quot;)
    
  )</code></pre>
<p><img src="processNZGGElecCons1minData_files/figure-html/allFileSizesPlot-1.png" /><!-- --></p>
<pre class="r"><code>ggplot2::ggsave(paste0(outPath, &quot;gridSpyAllFileListSizeTilePlot.png&quot;))</code></pre>
<pre><code>## Saving 7 x 5 in image</code></pre>
<p>The following chart shows the same chart but only for files which we think contain data.</p>
<pre class="r"><code>myCaption &lt;- paste0(&quot;Data source: &quot;, fpath,
                    &quot;\nUsing data received up to &quot;, Sys.Date())

plotDT &lt;- fListCompleteDT[!is.na(dateFormat), .(nFiles = .N,
                              meanfSize = mean(fSize)), 
                          keyby = .(hhID, date = as.Date(fMDate))]

ggplot2::ggplot(plotDT, aes( x = date, y = hhID, fill = log(meanfSize))) +
  geom_tile() +
  scale_fill_gradient(low = &quot;white&quot;, high = &quot;black&quot;) + 
  scale_x_date(date_labels = &quot;%Y %b&quot;, date_breaks = &quot;1 month&quot;) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) + 
  labs(title = &quot;Mean file size of loaded grid spy data files received per day&quot;,
       caption = paste0(myCaption, 
                        &quot;\nLog file size used as some files are full year data&quot;,
                        &quot;\nFiles loaded if fsize &gt; &quot;, dataThreshold, &quot; bytes&quot;)
    
  )</code></pre>
<p><img src="processNZGGElecCons1minData_files/figure-html/loadedFileSizesPlot-1.png" /><!-- --></p>
<pre class="r"><code>ggplot2::ggsave(paste0(outPath, &quot;gridSpyLoadedFileListSizeTilePlot.png&quot;))</code></pre>
<pre><code>## Saving 7 x 5 in image</code></pre>
</div>
</div>
<div id="load-data-files" class="section level1">
<h1><span class="header-section-number">4</span> Load data files</h1>
<p>In this section we load the data files that have a file size &gt; 3000 bytes. Things to note:</p>
<ul>
<li>We assume that any files smaller than this value have no observations. This is based on:
<ul>
<li>Manual inspection of several small files</li>
<li>The identical (small) file sizes involved</li>
<li><em>But</em> we should probably test the first few lines to double check…</li>
</ul></li>
<li>We have to deal with quite a lot of duplication some of which has caused the different date formats. See our <a href="https://git.soton.ac.uk/ba1e12/nzGREENGrid/issues?scope=all&amp;utf8=%E2%9C%93&amp;state=all">repo issues list</a>.</li>
</ul>
<p>The following table shows the number of files per household that we willl load.</p>
<pre class="r"><code>filesToLoadDT &lt;- fListCompleteDT[!is.na(dateFormat)]

t &lt;- filesToLoadDT[, .(nFiles = .N,
                       meanSize = mean(fSize),
                       minFileDate = min(fMDate),
                       maxFileDate = max(fMDate)), keyby = .(hhID)]

knitr::kable(caption = &quot;Summary of household files to load&quot;, t)</code></pre>
<table>
<caption>Summary of household files to load</caption>
<thead>
<tr class="header">
<th align="left">hhID</th>
<th align="right">nFiles</th>
<th align="right">meanSize</th>
<th align="left">minFileDate</th>
<th align="left">maxFileDate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">rf_01</td>
<td align="right">3</td>
<td align="right">15548174.7</td>
<td align="left">2016-09-20</td>
<td align="left">2016-09-30</td>
</tr>
<tr class="even">
<td align="left">rf_46</td>
<td align="right">411</td>
<td align="right">605048.1</td>
<td align="left">2016-06-08</td>
<td align="left">2018-02-21</td>
</tr>
</tbody>
</table>
<pre class="r"><code># &gt; Load, process &amp; save the ones which probably have data ----
fListCompleteDT &lt;- fListCompleteDT[, fileLoaded := &quot;No&quot;] # set default
hhIDs &lt;- unique(filesToLoadDT$hhID) # list of household ids
hhStatDT &lt;- data.table::data.table() # stats collector

for(hh in hhIDs){
  tempHhDT &lt;- data.table::data.table() # hh data collector
  print(paste0(&quot;Loading: &quot;, hh))
  filesToLoad &lt;- filesToLoadDT[hhID == hh, fullPath]
  for(f in filesToLoad){
    if(fullFb){print(paste0(&quot;File size (&quot;, f, &quot;) = &quot;, 
                            filesToLoadDT[fullPath == f, fSize], 
                            &quot; so probably OK&quot;))} # files under 3kb are probably empty
    # attempt to load the file
    tempDT &lt;- data.table::fread(f)
    if(fullFb){print(&quot;File loaded&quot;)}
    # set some file stats
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, fileLoaded := &quot;Yes&quot;]
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, nObs := nrow(tempDT)] # could include duplicates
    
    # what is the date column called?
      if(nrow(dplyr::select(tempDT, dplyr::contains(&quot;NZ&quot;))) &gt; 0){ # requires dplyr
        setnames(tempDT, &#39;date NZ&#39;, &quot;dateTime_char&quot;)
        tempDT &lt;- tempDT[, dateColName := &quot;date NZ&quot;]
      } 
      if(nrow(dplyr::select(tempDT, dplyr::contains(&quot;UTC&quot;))) &gt; 0){ # requires dplyr
        setnames(tempDT, &#39;date UTC&#39;, &quot;dateTime_char&quot;)
        tempDT &lt;- tempDT[, dateColName := &quot;date UTC&quot;]
      }
      
      # Now use the pre-inferred dateFormat
      tempDT &lt;- tempDT[, dateFormat := filesToLoadDT[fullPath == f, dateFormat]]
      tempDT &lt;- tempDT[dateFormat %like% &quot;mdy&quot; &amp; dateColName %like% &quot;NZ&quot;, r_dateTime := lubridate::mdy_hm(dateTime_char, tz = &quot;Pacific/Auckland&quot;)] # requires lubridate
      tempDT &lt;- tempDT[dateFormat %like% &quot;dmy&quot; &amp; dateColName %like% &quot;NZ&quot;, r_dateTime := lubridate::dmy_hm(dateTime_char, tz = &quot;Pacific/Auckland&quot;)] # requires lubridate
      tempDT &lt;- tempDT[dateFormat %like% &quot;ydm&quot; &amp; dateColName %like% &quot;NZ&quot;, r_dateTime := lubridate::ymd_hm(dateTime_char, tz = &quot;Pacific/Auckland&quot;)] # requires lubridate
      tempDT &lt;- tempDT[dateFormat %like% &quot;ymd&quot; &amp; dateColName %like% &quot;NZ&quot;, r_dateTime := lubridate::ymd_hm(dateTime_char, tz = &quot;Pacific/Auckland&quot;)] # requires lubridate
      tempDT &lt;- tempDT[dateFormat %like% &quot;mdy&quot; &amp; dateColName %like% &quot;UTC&quot;, r_dateTime := lubridate::mdy_hm(dateTime_char, tz = &quot;UTC&quot;)] # requires lubridate
      tempDT &lt;- tempDT[dateFormat %like% &quot;dmy&quot; &amp; dateColName %like% &quot;UTC&quot;, r_dateTime := lubridate::dmy_hm(dateTime_char, tz = &quot;UTC&quot;)] # requires lubridate
      tempDT &lt;- tempDT[dateFormat %like% &quot;ydm&quot; &amp; dateColName %like% &quot;UTC&quot;, r_dateTime := lubridate::ymd_hm(dateTime_char, tz = &quot;UTC&quot;)] # requires lubridate
      tempDT &lt;- tempDT[dateFormat %like% &quot;ymd&quot; &amp; dateColName %like% &quot;UTC&quot;, r_dateTime := lubridate::ymd_hm(dateTime_char, tz = &quot;UTC&quot;)] # requires lubridate
      if(fullFb){
        print(head(tempDT))
        print(summary(tempDT))
        #print(table(tempDT$dateFormat))
        }
    
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, obsStartDate := min(as.Date(tempDT$r_dateTime))] # should be a sensible number and not NA
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, obsEndDate := max(as.Date(tempDT$r_dateTime))] # should be a sensible number and not NA
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, nObs := nrow(tempDT)]
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, circuitLabels := toString(sort(colnames(dplyr::select(tempDT, 
                                                                                                            dplyr::contains(&quot;$&quot;)))))] # check the names of circuits - all seem to contain &quot;$&quot;; sort them to make it easier to compare them - this is the only way we have to check if data from different households has been placed in the wrong folder.
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, nCircuits := ncol(dplyr::select(tempDT, 
                                                                                      dplyr::contains(&quot;$&quot;)))] # check for the number of circuits - all seem to contain &quot;$&quot;
    #tempDT &lt;- tempDT[, sourceFile := f] # record for later checks - breaks de-duplication code
    # rbind to hh data collector
    tempHhDT &lt;- rbind(tempHhDT, tempDT, fill = TRUE) # fill just in case there are different numbers of columns or columns with different names (quite likely - crcuit labels may vary!)
  }
  
  # &gt; Remove duplicates caused by over-lapping files and dates etc ----
  # Need to remove all uneccessary vars for this to work
  # Any remaining duplicates will probably be due to over-lapping files which have different circuit labels - see table below
  try(tempHhDT$dateColName &lt;- NULL)
  try(tempHhDT$dateFormat &lt;- NULL)
  try(tempHhDT$dateTime_char &lt;- NULL) # if we leave this one in then we get duplicates where we have date NZ &amp; date UTC for the same timestamp due to overlapping file downloads
  
  nObs &lt;- nrow(tempHhDT)
  if(fullFb){print(paste0(&quot;N rows before removal of duplicates: &quot;, nObs))}
  tempHhDT &lt;- unique(tempHhDT)
  nObs &lt;- nrow(tempHhDT)
  if(fullFb){print(paste0(&quot;N rows after removal of duplicates: &quot;, nObs))}
  
  hhStatTempDT &lt;- tempHhDT[, .(nObs = .N,
                           nDataColumns = ncol(select(tempDT, contains(&quot;$&quot;)))), # the actual number of columns in the whole household file with &quot;$&quot; in them in case of rbind &quot;errors&quot; caused by files with different column names
                           keyby = (date = as.Date(r_dateTime))] # can&#39;t do sensible summary stats on W as some circuits are sub-sets of others!
  # add hhID
  hhStatTempDT &lt;- hhStatTempDT[, hhID := hh]
  
  hhStatDT &lt;- rbind(hhStatDT,hhStatTempDT) # add to the collector
  
  # &gt; Save hh file ----
  
  ofile &lt;- paste0(outPath, &quot;data/&quot;, hh,&quot;_all_1min_data.csv&quot;)
  print(paste0(&quot;Saving &quot;, ofile, &quot;...&quot;))
  write_csv(tempHhDT, ofile)
  print(paste0(&quot;Saved &quot;, ofile, &quot;, gzipping...&quot;))
  
  cmd &lt;- paste0(&quot;gzip -f &quot;, &quot;&#39;&quot;, path.expand(ofile), &quot;&#39;&quot;) # gzip it - use quotes in case of spaces in file name, expand path if needed
  try(system(cmd)) # in case it fails - if it does there will just be .csv files (not gzipped) - e.g. under windows
  print(paste0(&quot;Gzipped &quot;, ofile))
  
    if(fullFb){
    print(&quot;Col names: &quot;)
    print(names(tempHhDT))
    }
  
  tempHhDT &lt;- NULL # just in case
}</code></pre>
<pre><code>## [1] &quot;Loading: rf_01&quot;
## [1] &quot;Saving ~/Data/NZGreenGrid/gridspy/consolidated/1min/data/rf_01_all_1min_data.csv...&quot;
## [1] &quot;Saved ~/Data/NZGreenGrid/gridspy/consolidated/1min/data/rf_01_all_1min_data.csv, gzipping...&quot;
## [1] &quot;Gzipped ~/Data/NZGreenGrid/gridspy/consolidated/1min/data/rf_01_all_1min_data.csv&quot;
## [1] &quot;Loading: rf_46&quot;
## [1] &quot;Saving ~/Data/NZGreenGrid/gridspy/consolidated/1min/data/rf_46_all_1min_data.csv...&quot;
## [1] &quot;Saved ~/Data/NZGreenGrid/gridspy/consolidated/1min/data/rf_46_all_1min_data.csv, gzipping...&quot;
## [1] &quot;Gzipped ~/Data/NZGreenGrid/gridspy/consolidated/1min/data/rf_46_all_1min_data.csv&quot;</code></pre>
<pre class="r"><code>#&gt; Save observed data stats for all files loaded ----
ofile &lt;- paste0(outPath, &quot;hhDailyObservationsStats.csv&quot;)
print(paste0(&quot;Saving daily observations stats by hhid to &quot;, ofile)) # write out version with file stats</code></pre>
<pre><code>## [1] &quot;Saving daily observations stats by hhid to ~/Data/NZGreenGrid/gridspy/consolidated/1min/hhDailyObservationsStats.csv&quot;</code></pre>
<pre class="r"><code>write.csv(hhStatDT, ofile)
print(&quot;Done&quot;)</code></pre>
<pre><code>## [1] &quot;Done&quot;</code></pre>
<pre class="r"><code>ofile &lt;- paste0(outPath, fListFinal)
print(paste0(&quot;Saving 1 minute data files final metadata to &quot;, ofile))</code></pre>
<pre><code>## [1] &quot;Saving 1 minute data files final metadata to ~/Data/NZGreenGrid/gridspy/consolidated/1min/fListCompleteDT_final.csv&quot;</code></pre>
<pre class="r"><code>write.csv(fListCompleteDT, ofile)
print(&quot;Done&quot;)</code></pre>
<pre><code>## [1] &quot;Done&quot;</code></pre>
</div>
<div id="data-quality-analysis" class="section level1">
<h1><span class="header-section-number">5</span> Data quality analysis</h1>
<p>Now produce some data quality plots &amp; tables.</p>
<p>The following table shows the number of data files with different circuit labels by household. In theory there should only be one unique list per household and it should be present in every data file. If this is not the case then this implies that:</p>
<ul>
<li>some of the circuit labels for these households may have been changed during the data collection process;</li>
<li>some of the circuit labels may have character conversion errors which have changed the labels during the data collection process;</li>
<li>at least one file from one household has been saved to a folder containing data from a different household (unfortunately the raw data files do <em>not</em> contain household IDs in the data or the file names which would enable checking/preventative filtering). This will be visible in the table if two households appear to share <em>exactly</em> the same list of circuit labels.</li>
</ul>
<p>Some or all of these may be true at any given time!</p>
<p>If this table flags a lot of errors then some re-naming of the circuit labels (column names) may be necessary.</p>
<pre class="r"><code>t &lt;- fListCompleteDT[!is.na(circuitLabels), .(nFiles = .N,
                                              minObsDate = min(obsStartDate), # helps locate issues in data
                                              maxObsDate = max(obsEndDate),
                                              minFileDate = min(fMDate), # helps locate issues in files
                                              maxFileDate = max(fMDate),
                                              nObs = tidyNum(sum(nObs))),
                     keyby = .(circuitLabels,hhID)] # ignore NA - it is files not loaded due to size thresholds

knitr::kable(caption = &quot;Circuit labels list by household&quot;, t)</code></pre>
<table>
<caption>Circuit labels list by household</caption>
<thead>
<tr class="header">
<th align="left">circuitLabels</th>
<th align="left">hhID</th>
<th align="right">nFiles</th>
<th align="left">minObsDate</th>
<th align="left">maxObsDate</th>
<th align="left">minFileDate</th>
<th align="left">maxFileDate</th>
<th align="left">nObs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Heat Pumps (2x) &amp; Power$4232, Heat Pumps (2x) &amp; Power$4399, Hot Water - Controlled$4231, Hot Water - Controlled$4400, Incomer - Uncontrolled$4230, Incomer - Uncontrolled$4401, Incomer Voltage$4405, Kitchen &amp; Bedrooms$4229, Kitchen &amp; Bedrooms$4402, Laundry &amp; Bedrooms$4228, Laundry &amp; Bedrooms$4403, Lighting$4233, Lighting$4404</td>
<td align="left">rf_46</td>
<td align="right">408</td>
<td align="left">2015-05-24</td>
<td align="left">2018-02-19</td>
<td align="left">2016-06-08</td>
<td align="left">2018-02-21</td>
<td align="left">1,684,742</td>
</tr>
<tr class="even">
<td align="left">Heat Pumps (2x) &amp; Power1$4232, Heat Pumps (2x) &amp; Power2$4399, Hot Water - Controlled1$4231, Hot Water - Controlled2$4400, Incomer - Uncontrolled1$4230, Incomer - Uncontrolled2$4401, Incomer Voltage$4405, Kitchen &amp; Bedrooms1$4229, Kitchen &amp; Bedrooms2$4402, Laundry &amp; Bedrooms1$4228, Laundry &amp; Bedrooms2$4403, Lighting1$4233, Lighting2$4404</td>
<td align="left">rf_46</td>
<td align="right">1</td>
<td align="left">2016-10-11</td>
<td align="left">2017-11-20</td>
<td align="left">2017-11-21</td>
<td align="left">2017-11-21</td>
<td align="left">582,988</td>
</tr>
<tr class="odd">
<td align="left">Heat Pumps (2x) &amp; Power_Imag$4399, Heat Pumps (2x) &amp; Power$4232, Hot Water - Controlled_Imag$4400, Hot Water - Controlled$4231, Incomer - Uncontrolled_Imag$4401, Incomer - Uncontrolled$4230, Incomer Voltage$4405, Kitchen &amp; Bedrooms_Imag$4402, Kitchen &amp; Bedrooms$4229, Laundry &amp; Bedrooms_Imag$4403, Laundry &amp; Bedrooms$4228, Lighting_Imag$4404, Lighting$4233</td>
<td align="left">rf_46</td>
<td align="right">2</td>
<td align="left">2015-03-26</td>
<td align="left">2016-10-11</td>
<td align="left">2016-09-29</td>
<td align="left">2016-10-25</td>
<td align="left">261,377</td>
</tr>
<tr class="even">
<td align="left">Heating$1633, Hot water$1636, Kitchen power$1632, Lights$1635, Mains$1634, Range$1637</td>
<td align="left">rf_01</td>
<td align="right">3</td>
<td align="left">2014-01-05</td>
<td align="left">2015-10-20</td>
<td align="left">2016-09-20</td>
<td align="left">2016-09-30</td>
<td align="left">855,836</td>
</tr>
</tbody>
</table>
<p>The following plots show the number of observations per day per household. In theory we should not see:</p>
<ul>
<li>dates before 2014 or in to the future. These may indicate:
<ul>
<li>date conversion errors;</li>
</ul></li>
<li>more than 1440 observations per day. These may indicate:
<ul>
<li>duplicate time stamps - i.e. they have the same time stamps but different power (W) values or different circuit labels;</li>
<li>observations from files that are in the ‘wrong’ rf_XX folder and so are included in the ‘wrong’ household as ‘duplicate’ time stamps.</li>
</ul></li>
</ul>
<p>If present both of the latter may have been implied by the table above and would have evaded the de-duplication filter which simply checks each complete row against all others within it’s consolidated household dataset (a <em>within household absolute duplicate</em> check).</p>
<pre class="r"><code># short cut if already generated
# hhStatDT &lt;- as.data.table(read_csv(ofile)) # parses dates

# tile plot ----
ggplot2::ggplot(hhStatDT, aes( x = date, y = hhID, fill = nObs)) +
  geom_tile() +
  scale_fill_gradient(low = &quot;red&quot;, high = &quot;green&quot;) +
  scale_x_date(date_labels = &quot;%Y %b&quot;, date_breaks = &quot;6 months&quot;) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) + 
  labs(title = &quot;N observations per household per day for all loaded grid spy data&quot;,
       caption = paste0(myCaption,
                        &quot;\nOnly files of size &gt; &quot;, dataThreshold, &quot; bytes loaded&quot;)
       
  )</code></pre>
<p><img src="processNZGGElecCons1minData_files/figure-html/loadedFilesObsPlots-1.png" /><!-- --></p>
<pre class="r"><code>ggplot2::ggsave(paste0(outPath, &quot;gridSpyLoadedFileNobsTilePlot.png&quot;))</code></pre>
<pre><code>## Saving 7 x 5 in image</code></pre>
<pre class="r"><code># point plot ----
ggplot2::ggplot(hhStatDT, aes( x = date, y = nObs, colour = hhID)) +
  geom_point() +
  scale_x_date(date_labels = &quot;%Y %b&quot;, date_breaks = &quot;6 months&quot;) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) + 
  labs(title = &quot;N observations per household per day for all loaded grid spy data&quot;,
       caption = paste0(myCaption,
                        &quot;\nOnly files of size &gt; &quot;, dataThreshold, &quot; bytes loaded&quot;)
       
  )</code></pre>
<p><img src="processNZGGElecCons1minData_files/figure-html/loadedFilesObsPlots-2.png" /><!-- --></p>
<pre class="r"><code>ggplot2::ggsave(paste0(outPath, &quot;gridSpyLoadedFileNobsPointPlot.png&quot;))</code></pre>
<pre><code>## Saving 7 x 5 in image</code></pre>
<p>The following table shows the min/max observations per day and min/max dates for each household. As above, we should not see:</p>
<ul>
<li>dates before 2014 or in to the future (indicates date conversion errors)</li>
<li>more than 1440 observations per day (indicates potentially duplicate observations)</li>
<li>non-integer counts of circuits as it suggests some column errors</li>
</ul>
<p>We should also not see NA in any row (indicates date conversion errors).</p>
<p>If we do see any of these then we still have data cleaning work to do!</p>
<pre class="r"><code># Stats table (so we can pick out the dateTime errors)
t &lt;- hhStatDT[, .(minObs = min(nObs),
             maxObs = max(nObs), # should not be more than 1440, if so suggests duplicates
             meanNDataColumns =mean(nDataColumns), #i.e. n circuits
             minDate = min(date),
             maxDate = max(date)),
         keyby = .(hhID)]

knitr::kable(caption = &quot;Summary observation stats by hhID&quot;, t)</code></pre>
<table>
<caption>Summary observation stats by hhID</caption>
<thead>
<tr class="header">
<th align="left">hhID</th>
<th align="right">minObs</th>
<th align="right">maxObs</th>
<th align="right">meanNDataColumns</th>
<th align="left">minDate</th>
<th align="left">maxDate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">rf_01</td>
<td align="right">171</td>
<td align="right">1500</td>
<td align="right">6</td>
<td align="left">2014-01-05</td>
<td align="left">2015-10-20</td>
</tr>
<tr class="even">
<td align="left">rf_46</td>
<td align="right">305</td>
<td align="right">3000</td>
<td align="right">13</td>
<td align="left">2015-03-26</td>
<td align="left">2018-02-19</td>
</tr>
</tbody>
</table>
<p>Finally we show the total number of households which we think are still sending data.</p>
<pre class="r"><code>plotDT &lt;- hhStatDT[, .(nHH = uniqueN(hhID)), keyby = .(date)]

# point plot ----
ggplot2::ggplot(plotDT, aes( x = date, y = nHH)) +
  geom_point() +
  scale_x_date(date_labels = &quot;%Y %b&quot;, date_breaks = &quot;6 months&quot;) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) + 
  labs(title = &quot;N live households per day for all loaded grid spy data&quot;,
       caption = paste0(myCaption,
                        &quot;\nOnly files of size &gt; &quot;, dataThreshold, &quot; bytes loaded&quot;)
       
  )</code></pre>
<p><img src="processNZGGElecCons1minData_files/figure-html/liveDataHouseholds-1.png" /><!-- --></p>
<pre class="r"><code>ggplot2::ggsave(paste0(outPath, &quot;gridSpyLiveHouseholdsToDate.png&quot;))</code></pre>
<pre><code>## Saving 7 x 5 in image</code></pre>
</div>
<div id="runtime" class="section level1">
<h1><span class="header-section-number">6</span> Runtime</h1>
<pre class="r"><code>t &lt;- proc.time() - startTime

elapsed &lt;- t[[3]]</code></pre>
<p>Analysis completed in 425.465 seconds ( 7.09 minutes) using <a href="https://cran.r-project.org/package=knitr">knitr</a> in <a href="http://www.rstudio.com">RStudio</a> with R version 3.4.4 (2018-03-15) running on x86_64-apple-darwin15.6.0.</p>
</div>
<div id="r-environment" class="section level1">
<h1><span class="header-section-number">7</span> R environment</h1>
<p>R packages used: data.table, lubridate, ggplot2, readr, dplyr, knitr</p>
<ul>
<li>base R - for the basics <span class="citation">(R Core Team 2016)</span></li>
<li>data.table - for fast (big) data handling <span class="citation">(Dowle et al. 2015)</span></li>
<li>lubridate - date manipulation <span class="citation">(Grolemund and Wickham 2011)</span></li>
<li>ggplot2 - for slick graphics <span class="citation">(Wickham 2009)</span></li>
<li>readr - for csv reading/writing <span class="citation">(Wickham, Hester, and Francois 2016)</span></li>
<li>dplyr - for select and contains <span class="citation">(Wickham and Francois 2016)</span></li>
<li>knitr - to create this document <span class="citation">(Xie 2016)</span></li>
<li>greenGridr - for local NZ GREEN Grid utilities</li>
</ul>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.4.4 (2018-03-15)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.4
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] knitr_1.20          dplyr_0.7.4         readr_1.1.1        
## [4] ggplot2_2.2.1       lubridate_1.7.4     data.table_1.10.4-3
## [7] greenGridr_0.1.0   
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_0.12.16      bindr_0.1.1       magrittr_1.5     
##  [4] hms_0.4.2         munsell_0.4.3     colorspace_1.3-2 
##  [7] R6_2.2.2          rlang_0.2.0.9001  highr_0.6        
## [10] stringr_1.3.0     plyr_1.8.4        tools_3.4.4      
## [13] grid_3.4.4        gtable_0.2.0      htmltools_0.3.6  
## [16] assertthat_0.2.0  yaml_2.1.18       lazyeval_0.2.1   
## [19] rprojroot_1.3-2   digest_0.6.15     tibble_1.4.2     
## [22] bindrcpp_0.2.2    glue_1.2.0        evaluate_0.10.1  
## [25] rmarkdown_1.9     labeling_0.3      stringi_1.1.7    
## [28] compiler_3.4.4    pillar_1.2.2      scales_0.5.0.9000
## [31] backports_1.1.2   pkgconfig_2.0.1</code></pre>
<div id="refs" class="references">
<div id="ref-data.table">
<p>Dowle, M, A Srinivasan, T Short, S Lianoglou with contributions from R Saporta, and E Antonyan. 2015. <em>Data.table: Extension of Data.frame</em>. <a href="https://CRAN.R-project.org/package=data.table" class="uri">https://CRAN.R-project.org/package=data.table</a>.</p>
</div>
<div id="ref-lubridate">
<p>Grolemund, Garrett, and Hadley Wickham. 2011. “Dates and Times Made Easy with lubridate.” <em>Journal of Statistical Software</em> 40 (3): 1–25. <a href="http://www.jstatsoft.org/v40/i03/" class="uri">http://www.jstatsoft.org/v40/i03/</a>.</p>
</div>
<div id="ref-baseR">
<p>R Core Team. 2016. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/" class="uri">https://www.R-project.org/</a>.</p>
</div>
<div id="ref-ggplot2">
<p>Wickham, Hadley. 2009. <em>Ggplot2: Elegant Graphics for Data Analysis</em>. Springer-Verlag New York. <a href="http://ggplot2.org" class="uri">http://ggplot2.org</a>.</p>
</div>
<div id="ref-dplyr">
<p>Wickham, Hadley, and Romain Francois. 2016. <em>Dplyr: A Grammar of Data Manipulation</em>. <a href="https://CRAN.R-project.org/package=dplyr" class="uri">https://CRAN.R-project.org/package=dplyr</a>.</p>
</div>
<div id="ref-readr">
<p>Wickham, Hadley, Jim Hester, and Romain Francois. 2016. <em>Readr: Read Tabular Data</em>. <a href="https://CRAN.R-project.org/package=readr" class="uri">https://CRAN.R-project.org/package=readr</a>.</p>
</div>
<div id="ref-knitr">
<p>Xie, Yihui. 2016. <em>Knitr: A General-Purpose Package for Dynamic Report Generation in R</em>. <a href="https://CRAN.R-project.org/package=knitr" class="uri">https://CRAN.R-project.org/package=knitr</a>.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
