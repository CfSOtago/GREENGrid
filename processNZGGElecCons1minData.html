<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Ben Anderson (b.anderson@soton.ac.uk, @dataknut)" />


<title>Processing, cleaning and saving NZ GREEN Grid project 1 minute electricity consumption data</title>

<script src="processNZGGElecCons1minData_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="processNZGGElecCons1minData_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="processNZGGElecCons1minData_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="processNZGGElecCons1minData_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="processNZGGElecCons1minData_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="processNZGGElecCons1minData_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="processNZGGElecCons1minData_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="processNZGGElecCons1minData_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="processNZGGElecCons1minData_files/navigation-1.1/tabsets.js"></script>
<script src="processNZGGElecCons1minData_files/navigation-1.1/codefolding.js"></script>
<link href="processNZGGElecCons1minData_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="processNZGGElecCons1minData_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Processing, cleaning and saving NZ GREEN Grid project 1 minute electricity consumption data</h1>
<h4 class="author"><em>Ben Anderson (<a href="mailto:b.anderson@soton.ac.uk">b.anderson@soton.ac.uk</a>, <code>@dataknut</code>)</em></h4>
<h4 class="date"><em>Last run at: 2018-05-03 10:19:42</em></h4>

</div>



<div id="citation" class="section level1">
<h1><span class="header-section-number">1</span> Citation</h1>
<p>If you wish to use any of the material from this report please cite as:</p>
<ul>
<li>Anderson, B. (2018) Processing, cleaning and saving NZ GREEN Grid project 1 minute electricity consumption data, University of Otago: Dunedin, NZ.</li>
</ul>

</div>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">2</span> Introduction</h1>
<p>Report circulation:</p>
<ul>
<li>Restricted to: <a href="https://www.otago.ac.nz/centre-sustainability/research/energy/otago050285.html">NZ GREEn Grid</a> project partners and contractors.</li>
</ul>
<div id="purpose" class="section level2">
<h2><span class="header-section-number">2.1</span> Purpose</h2>
<p>This report is intended to:</p>
<ul>
<li>load and clean the project electricity consumption data (Grid Spy)</li>
<li>save the cleaned data out as a single file per household</li>
<li>produce summary data quality statistics</li>
</ul>
</div>
<div id="requirements" class="section level2">
<h2><span class="header-section-number">2.2</span> Requirements:</h2>
<ul>
<li>grid spy 1 minute data downloads</li>
</ul>
</div>
<div id="history" class="section level2">
<h2><span class="header-section-number">2.3</span> History</h2>
<p>Generally tracked via our git.soton <a href="https://git.soton.ac.uk/ba1e12/nzGREENGrid">repo</a>.</p>
</div>
<div id="support" class="section level2">
<h2><span class="header-section-number">2.4</span> Support</h2>
<p>This work was supported by:</p>
<ul>
<li>The <a href="https://www.otago.ac.nz/">University of Otago</a></li>
<li>The New Zealand <a href="http://www.mbie.govt.nz/">Ministry of Business, Innovation and Employment (MBIE)</a></li>
<li><a href="http://www.energy.soton.ac.uk/tag/spatialec/">SPATIALEC</a> - a <a href="http://ec.europa.eu/research/mariecurieactions/about-msca/actions/if/index_en.htm">Marie Skłodowska-Curie Global Fellowship</a> based at the University of Otago’s <a href="http://www.otago.ac.nz/centre-sustainability/staff/otago673896.html">Centre for Sustainability</a> (2017-2019) &amp; the University of Southampton’s Sustainable Energy Research Group (2019-202).</li>
</ul>
<p>This work uis (c) 2018 the University of Southampton.</p>
</div>
</div>
<div id="obtain-listing-of-files" class="section level1">
<h1><span class="header-section-number">3</span> Obtain listing of files</h1>
<p>In this section we generate a listing of all 1 minute data files that we have received. If we are running over the complete dataset then we will be using data from:</p>
<ul>
<li>/hum-csafe/Research Projects/GREEN Grid/_RAW DATA/GridSpyData/</li>
</ul>
<p>In this run we are using data from:</p>
<ul>
<li>~/Data/NZGreenGrid/gridspy/1min_orig/</li>
</ul>
<p>If these do not match then this may be a test run.</p>
<pre class="r"><code>print(paste0(&quot;Looking for 1 minute data using pattern = &quot;, pattern1Min, &quot; in &quot;, fpath, &quot; - could take a while&quot;))</code></pre>
<pre><code>## [1] &quot;Looking for 1 minute data using pattern = *at1.csv$ in ~/Data/NZGreenGrid/gridspy/1min_orig/ - could take a while&quot;</code></pre>
<pre class="r"><code>system.time(fListCompleteDT &lt;- as.data.table(list.files(path = fpath, pattern = pattern1Min, # use the default pattern to filter e.g. 1m from 30s files
                                            recursive = TRUE)))</code></pre>
<pre><code>##    user  system elapsed 
##   0.014   0.017   0.040</code></pre>
<pre class="r"><code>nFiles &lt;- nrow(fListCompleteDT)
print(paste0(&quot;Found &quot;, nFiles, &quot; files&quot;))</code></pre>
<pre><code>## [1] &quot;Found 1915 files&quot;</code></pre>
<pre class="r"><code>if(nrow(fListCompleteDT) == 0){
  stop(paste0(&quot;No matching data files found, please check your path (&quot;, fpath, &quot;) or your search pattern (&quot;, pattern1Min, &quot;)&quot;))
} else {
  print(paste0(&quot;Processing file list and getting file meta-data (please be patient)&quot;))
  fListCompleteDT &lt;- fListCompleteDT[, c(&quot;hhID&quot;,&quot;fileName&quot;) := tstrsplit(V1, &quot;/&quot;)]
  fListCompleteDT &lt;- fListCompleteDT[, fullPath := paste0(fpath, hhID,&quot;/&quot;,fileName)]
  loopCount &lt;- 1
  # now loop over the files and collect metadata
  for(f in fListCompleteDT[,fullPath]){
    pcDone &lt;- 100*(loopCount/nFiles)
    if(fullFb){print(paste0(&quot;Checking file &quot;, loopCount, &quot; of &quot;, nFiles ,
                            &quot; (&quot;, round(pcDone,2), &quot;% checked) - &quot;, f))}
    rf &lt;- path.expand(f) # just in case of ~ etc
    fsize &lt;- file.size(rf)
    fmtime &lt;- ymd_hms(file.mtime(rf), tz = &quot;Pacific/Auckland&quot;) # requires lubridate
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, fSize := fsize]
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, fMTime := fmtime]
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, fMDate := as.Date(fmtime)]
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, dateColName := paste0(&quot;unknown - file not loaded (fsize = &quot;, fsize, &quot;)&quot;)]
    # only try to read files where we think there might be data
    if(fsize &gt; dataThreshold){
      if(fullFb){print(paste0(&quot;fSize (&quot;, fsize, &quot;) &gt; threshold (&quot;, dataThreshold, &quot;) -&gt; loading &quot;, f))}
      row1DT &lt;- fread(f, nrows = 1)
      # what is the date column called?
      fListCompleteDT &lt;- fListCompleteDT[fullPath == f, dateColName := &quot;unknown - can&#39;t tell&quot;]
      if(nrow(select(row1DT, contains(&quot;NZ&quot;))) &gt; 0){ # requires dplyr
        setnames(row1DT, &#39;date NZ&#39;, &quot;dateTime_char&quot;)
        row1DT &lt;- row1DT[, dateColName := &quot;date NZ&quot;]
        fListCompleteDT &lt;- fListCompleteDT[fullPath == f, dateColName := &quot;date NZ&quot;]
      } 
      if(nrow(select(row1DT, contains(&quot;UTC&quot;))) &gt; 0){ # requires dplyr
        setnames(row1DT, &#39;date UTC&#39;, &quot;dateTime_char&quot;)
        row1DT &lt;- row1DT[, dateColName := &quot;date UTC&quot;]
        fListCompleteDT &lt;- fListCompleteDT[fullPath == f, dateColName := &quot;date UTC&quot;]
      }
      # split dateTime
      row1DT &lt;- row1DT[, c(&quot;date_char&quot;, &quot;time_char&quot;) := tstrsplit(dateTime_char, &quot; &quot;)]
      # add example of date to metadata - presumably they are the same in each file?!
      fListCompleteDT &lt;- fListCompleteDT[fullPath == f, dateExample := row1DT[1, date_char]]
      
      if(fullFb){print(paste0(&quot;Checking date formats in &quot;, f))}
      dt &lt;- gs_checkDates(row1DT)
      fListCompleteDT &lt;- fListCompleteDT[fullPath == f, dateFormat := dt[1, dateFormat]]
      if(fullFb){print(paste0(&quot;Done &quot;, f))}
    }
    loopCount &lt;- loopCount + 1
  }
  if(baTest | fullFb){print(&quot;All files checked&quot;)}
  # any date formats are still ambiguous need a deeper inspection using the full file - could be slow
  fAmbig &lt;- fListCompleteDT[dateFormat == &quot;ambiguous&quot;, fullPath]
  
  for(fa in fAmbig){
    if(baTest | fullFb){print(paste0(&quot;Checking ambiguous date formats in &quot;, fa))}
    dt &lt;- fread(fa)
    if(nrow(select(dt, contains(&quot;NZ&quot;))) &gt; 0){ # requires dplyr
      setnames(dt, &#39;date NZ&#39;, &quot;dateTime_char&quot;)
      
    } 
    if(nrow(select(dt, contains(&quot;UTC&quot;))) &gt; 0){ # requires dplyr
      setnames(dt, &#39;date UTC&#39;, &quot;dateTime_char&quot;)
      
    }
    dt &lt;- dt[, c(&quot;date_char&quot;, &quot;time_char&quot;) := tstrsplit(dateTime_char, &quot; &quot;)]
    dt &lt;- gs_checkDates(dt)
    # set what we now know (or guess!)
    fListCompleteDT &lt;- fListCompleteDT[fullPath == fa, dateFormat := dt[1,dateFormat]]
  }
      
  ofile &lt;- paste0(outPath, indexFile)
  print(paste0(&quot;Saving 1 minute data files metadata to &quot;, ofile))
  write.csv(fListCompleteDT, ofile)
  print(&quot;Done&quot;)
}</code></pre>
<pre><code>## [1] &quot;Processing file list and getting file meta-data (please be patient)&quot;
## [1] &quot;All files checked&quot;
## [1] &quot;Checking ambiguous date formats in ~/Data/NZGreenGrid/gridspy/1min_orig/rf_25/12Oct2016-20Nov2017at1.csv&quot;
## [1] &quot;Checking ambiguous date formats in ~/Data/NZGreenGrid/gridspy/1min_orig/rf_46/12Oct2016-20Nov2017at1.csv&quot;
## [1] &quot;Saving 1 minute data files metadata to ~/Data/NZGreenGrid/gridspy/consolidated/fListCompleteDT.csv&quot;
## [1] &quot;Done&quot;</code></pre>
<pre class="r"><code>print(paste0(&quot;Overall we have &quot;, nrow(fListCompleteDT), &quot; files from &quot;, uniqueN(fListCompleteDT$hhID), &quot; households.&quot;))</code></pre>
<pre><code>## [1] &quot;Overall we have 1915 files from 4 households.&quot;</code></pre>
<pre class="r"><code># for use below
nFiles &lt;- nrow(fListCompleteDT)
nFilesNotLoaded &lt;- nrow(fListCompleteDT[dateColName %like% &quot;unknown&quot;])</code></pre>
<p>Overall we have 1,915 files from 4 households. Of the 1,915, 1,495 (78.07%) were <em>not</em> loaded/checked as their file sizes indicated that they contained no data.</p>
<p>We now need to check how many of the loaded files have an ambiguous or default date - these could introduce errors.</p>
<pre class="r"><code>t &lt;- fListCompleteDT[, .(nFiles = .N), keyby = .(dateColName, dateFormat)]

kable(caption = &quot;Number of files with given date column names by inferred date format&quot;, t)</code></pre>
<table>
<caption>Number of files with given date column names by inferred date format</caption>
<thead>
<tr class="header">
<th align="left">dateColName</th>
<th align="left">dateFormat</th>
<th align="right">nFiles</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">date NZ</td>
<td align="left">dmy</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">date NZ</td>
<td align="left">mdy</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">date NZ</td>
<td align="left">ymd</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="left">date NZ</td>
<td align="left">ymd - default (check as m &amp; d may be reversed)</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">date UTC</td>
<td align="left">ambiguous</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">date UTC</td>
<td align="left">ymd</td>
<td align="right">248</td>
</tr>
<tr class="odd">
<td align="left">date UTC</td>
<td align="left">ymd - default (check as m &amp; d may be reversed)</td>
<td align="right">161</td>
</tr>
<tr class="even">
<td align="left">unknown - file not loaded (fsize = 2751)</td>
<td align="left">NA</td>
<td align="right">604</td>
</tr>
<tr class="odd">
<td align="left">unknown - file not loaded (fsize = 43)</td>
<td align="left">NA</td>
<td align="right">891</td>
</tr>
</tbody>
</table>
<p>Results to note:</p>
<ul>
<li>There are 2 ambiguous files</li>
<li>The non-loaded files only have 2 distinct file sizes, confirming that they are unlikely to contain useful data.</li>
</ul>
<p>We now inspect the ambiguous and (some of) the default files.</p>
<p>To help with data cleaning the following table lists files that are ambiguous.</p>
<pre class="r"><code># list ambigious files
aList &lt;- fListCompleteDT[dateFormat == &quot;ambiguous&quot;, .(file = V1, dateColName, dateExample, dateFormat)]

kable(caption = &quot;Files with ambigious date formats&quot;, aList)</code></pre>
<table>
<caption>Files with ambigious date formats</caption>
<thead>
<tr class="header">
<th align="left">file</th>
<th align="left">dateColName</th>
<th align="left">dateExample</th>
<th align="left">dateFormat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">rf_25/12Oct2016-20Nov2017at1.csv</td>
<td align="left">date UTC</td>
<td align="left">11-10-16</td>
<td align="left">ambiguous</td>
</tr>
<tr class="even">
<td align="left">rf_46/12Oct2016-20Nov2017at1.csv</td>
<td align="left">date UTC</td>
<td align="left">11-10-16</td>
<td align="left">ambiguous</td>
</tr>
</tbody>
</table>
<p>Looking at the file names we will assume they are dmy.</p>
<pre class="r"><code>fListCompleteDT &lt;- fListCompleteDT[dateFormat == &quot;ambiguous&quot;, dateFormat := &quot;dmy - inferred&quot;]</code></pre>
<p>The following table lists ‘date NZ’ files which are set by default only - do they look OK to assume dateFormat?</p>
<pre class="r"><code># list default files
aList &lt;- fListCompleteDT[dateColName == &quot;date NZ&quot; &amp; dateFormat %like% &quot;default&quot;, .(file = V1, fSize, dateColName, dateExample, dateFormat)]

kable(caption = &quot;Files with inferred default date formats&quot;, head(aList))</code></pre>
<table>
<caption>Files with inferred default date formats</caption>
<thead>
<tr class="header">
<th align="left">file</th>
<th align="right">fSize</th>
<th align="left">dateColName</th>
<th align="left">dateExample</th>
<th align="left">dateFormat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">rf_01/1Jan2014-24May2014at1.csv</td>
<td align="right">6255737</td>
<td align="left">date NZ</td>
<td align="left">2014-01-06</td>
<td align="left">ymd - default (check as m &amp; d may be reversed)</td>
</tr>
<tr class="even">
<td align="left">rf_02/1Jan2014-24May2014at1.csv</td>
<td align="right">6131625</td>
<td align="left">date NZ</td>
<td align="left">2014-03-03</td>
<td align="left">ymd - default (check as m &amp; d may be reversed)</td>
</tr>
</tbody>
</table>
<p>These look OK if we compare the file names with the dateExample.</p>
<p>The following table lists ‘date NZ’ files which are set by default only - do they look OK to assume dateFormat?</p>
<pre class="r"><code># list default files
aList &lt;- fListCompleteDT[dateColName == &quot;date UTC&quot; &amp; dateFormat %like% &quot;default&quot;, .(file = V1, fSize, dateColName, dateExample, dateFormat)]

kable(caption = &quot;Files with inferred default date formats&quot;, head(aList))</code></pre>
<table>
<caption>Files with inferred default date formats</caption>
<thead>
<tr class="header">
<th align="left">file</th>
<th align="right">fSize</th>
<th align="left">dateColName</th>
<th align="left">dateExample</th>
<th align="left">dateFormat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">rf_46/10Apr2017-11Apr2017at1.csv</td>
<td align="right">292721</td>
<td align="left">date UTC</td>
<td align="left">2017-04-09</td>
<td align="left">ymd - default (check as m &amp; d may be reversed)</td>
</tr>
<tr class="even">
<td align="left">rf_46/10Aug2017-11Aug2017at1.csv</td>
<td align="right">292888</td>
<td align="left">date UTC</td>
<td align="left">2017-08-09</td>
<td align="left">ymd - default (check as m &amp; d may be reversed)</td>
</tr>
<tr class="odd">
<td align="left">rf_46/10Dec2017-11Dec2017at1.csv</td>
<td align="right">292823</td>
<td align="left">date UTC</td>
<td align="left">2017-12-09</td>
<td align="left">ymd - default (check as m &amp; d may be reversed)</td>
</tr>
<tr class="even">
<td align="left">rf_46/10Feb2017-11Feb2017at1.csv</td>
<td align="right">286736</td>
<td align="left">date UTC</td>
<td align="left">2017-02-09</td>
<td align="left">ymd - default (check as m &amp; d may be reversed)</td>
</tr>
<tr class="odd">
<td align="left">rf_46/10Feb2018-11Feb2018at1.csv</td>
<td align="right">299084</td>
<td align="left">date UTC</td>
<td align="left">2018-02-09</td>
<td align="left">ymd - default (check as m &amp; d may be reversed)</td>
</tr>
<tr class="even">
<td align="left">rf_46/10Jan2017-11Jan2017at1.csv</td>
<td align="right">297659</td>
<td align="left">date UTC</td>
<td align="left">2017-01-09</td>
<td align="left">ymd - default (check as m &amp; d may be reversed)</td>
</tr>
</tbody>
</table>
<p>These also look OK so we will stick with the following derived date formats:</p>
<pre class="r"><code>t &lt;- fListCompleteDT[, .(nFiles = .N), keyby = .(dateColName, dateFormat)]

kable(caption = &quot;Number of files with given date column names by final imputed date format&quot;, t)</code></pre>
<table>
<caption>Number of files with given date column names by final imputed date format</caption>
<thead>
<tr class="header">
<th align="left">dateColName</th>
<th align="left">dateFormat</th>
<th align="right">nFiles</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">date NZ</td>
<td align="left">dmy</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">date NZ</td>
<td align="left">mdy</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">date NZ</td>
<td align="left">ymd</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="left">date NZ</td>
<td align="left">ymd - default (check as m &amp; d may be reversed)</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">date UTC</td>
<td align="left">dmy - inferred</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">date UTC</td>
<td align="left">ymd</td>
<td align="right">248</td>
</tr>
<tr class="odd">
<td align="left">date UTC</td>
<td align="left">ymd - default (check as m &amp; d may be reversed)</td>
<td align="right">161</td>
</tr>
<tr class="even">
<td align="left">unknown - file not loaded (fsize = 2751)</td>
<td align="left">NA</td>
<td align="right">604</td>
</tr>
<tr class="odd">
<td align="left">unknown - file not loaded (fsize = 43)</td>
<td align="left">NA</td>
<td align="right">891</td>
</tr>
</tbody>
</table>
<div id="data-file-quality-checks" class="section level2">
<h2><span class="header-section-number">3.1</span> Data file quality checks</h2>
<p>The following chart shows the distribution of these files over time using their sizes. Note that white indicates the presence of small files which may not contain observations.</p>
<pre class="r"><code>myCaption &lt;- paste0(&quot;Data source: &quot;, fpath,
                    &quot;\nUsing data received up to &quot;, Sys.Date())

plotDT &lt;- fListCompleteDT[, .(nFiles = .N,
                              meanfSize = mean(fSize)), 
                          keyby = .(hhID, date = as.Date(fMDate))]

ggplot(plotDT, aes( x = date, y = hhID, fill = log(meanfSize))) +
  geom_tile() +
  scale_fill_gradient(low = &quot;white&quot;, high = &quot;black&quot;) + 
  scale_x_date(date_labels = &quot;%Y %b&quot;, date_breaks = &quot;1 month&quot;) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) + 
  labs(title = &quot;Mean file size of all grid spy data files received per day&quot;,
       caption = paste0(myCaption, 
                        &quot;\nLog file size used as some files are full year data&quot;)
    
  )</code></pre>
<p><img src="processNZGGElecCons1minData_files/figure-html/allFileSizesPlot-1.png" /><!-- --></p>
<pre class="r"><code>ggsave(paste0(outPath, &quot;gridSpyAllFileListSizeTilePlot.png&quot;))</code></pre>
<pre><code>## Saving 7 x 5 in image</code></pre>
<p>The following chart shows the same chart but only for files which we think contain data.</p>
<pre class="r"><code>myCaption &lt;- paste0(&quot;Data source: &quot;, fpath,
                    &quot;\nUsing data received up to &quot;, Sys.Date())

plotDT &lt;- fListCompleteDT[!is.na(dateFormat), .(nFiles = .N,
                              meanfSize = mean(fSize)), 
                          keyby = .(hhID, date = as.Date(fMDate))]

ggplot(plotDT, aes( x = date, y = hhID, fill = log(meanfSize))) +
  geom_tile() +
  scale_fill_gradient(low = &quot;white&quot;, high = &quot;black&quot;) + 
  scale_x_date(date_labels = &quot;%Y %b&quot;, date_breaks = &quot;1 month&quot;) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) + 
  labs(title = &quot;Mean file size of all grid spy data files received per day&quot;,
       caption = paste0(myCaption, 
                        &quot;\nLog file size used as some files are full year data&quot;)
    
  )</code></pre>
<p><img src="processNZGGElecCons1minData_files/figure-html/loadedFileSizesPlot-1.png" /><!-- --></p>
<pre class="r"><code>ggsave(paste0(outPath, &quot;gridSpyLoadedFileListSizeTilePlot.png&quot;))</code></pre>
<pre><code>## Saving 7 x 5 in image</code></pre>
</div>
</div>
<div id="load-data-files" class="section level1">
<h1><span class="header-section-number">4</span> Load data files</h1>
<p>In this section we load the data files that have a file size &gt; 3000 bytes. Things to note:</p>
<ul>
<li>We assume that any files smaller than this value have no observations. This is based on:
<ul>
<li>Manual inspection of several small files</li>
<li>The identical (small) file sizes involved</li>
<li><em>But</em> we should probably test the first few lines to double check…</li>
</ul></li>
<li>We have to deal with quite a lot of duplication some of which has caused the different date formats. See our <a href="https://git.soton.ac.uk/ba1e12/nzGREENGrid/issues?scope=all&amp;utf8=%E2%9C%93&amp;state=all">repo issues list</a>.</li>
</ul>
<p>The following table shows the number of files per household that we willl load.</p>
<pre class="r"><code>filesToLoadDT &lt;- fListCompleteDT[!is.na(dateFormat)]

t &lt;- filesToLoadDT[, .(nFiles = .N,
                       meanSize = mean(fSize),
                       minFileDate = min(fMDate),
                       maxFileDate = max(fMDate)), keyby = .(hhID)]

kable(caption = &quot;Summary of household files to load&quot;, t)</code></pre>
<table>
<caption>Summary of household files to load</caption>
<thead>
<tr class="header">
<th align="left">hhID</th>
<th align="right">nFiles</th>
<th align="right">meanSize</th>
<th align="left">minFileDate</th>
<th align="left">maxFileDate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">rf_01</td>
<td align="right">3</td>
<td align="right">15548174.7</td>
<td align="left">2016-09-20</td>
<td align="left">2016-09-30</td>
</tr>
<tr class="even">
<td align="left">rf_02</td>
<td align="right">3</td>
<td align="right">10134268.3</td>
<td align="left">2016-09-20</td>
<td align="left">2016-09-30</td>
</tr>
<tr class="odd">
<td align="left">rf_25</td>
<td align="right">3</td>
<td align="right">12341581.3</td>
<td align="left">2016-06-08</td>
<td align="left">2017-11-21</td>
</tr>
<tr class="even">
<td align="left">rf_46</td>
<td align="right">411</td>
<td align="right">605048.1</td>
<td align="left">2016-06-08</td>
<td align="left">2018-02-21</td>
</tr>
</tbody>
</table>
<pre class="r"><code># &gt; Load, process &amp; save the ones which probably have data ----
fListCompleteDT &lt;- fListCompleteDT[, fileLoaded := &quot;No&quot;] # set default
hhIDs &lt;- unique(filesToLoadDT$hhID) # list of household ids
hhStatDT &lt;- data.table() # stats collector
for(hh in hhIDs){
  tempHhDT &lt;- data.table() # hh data collector
  print(paste0(&quot;Loading: &quot;, hh))
  filesToLoad &lt;- filesToLoadDT[hhID == hh, fullPath]
  for(f in filesToLoad){
    if(fullFb){print(paste0(&quot;File size (&quot;, f, &quot;) = &quot;, 
                            filesToLoadDT[fullPath == f, fSize], 
                            &quot; so probably OK&quot;))} # files under 3kb are probably empty
    # attempt to load the file
    tempDT &lt;- fread(f)
    if(fullFb){print(&quot;File loaded&quot;)}
    # set some file stats
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, fileLoaded := &quot;Yes&quot;]
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, nObs := nrow(tempDT)] # could include duplicates
    
    # what is the date column called?
      if(nrow(select(tempDT, contains(&quot;NZ&quot;))) &gt; 0){ # requires dplyr
        setnames(tempDT, &#39;date NZ&#39;, &quot;dateTime_char&quot;)
        tempDT &lt;- tempDT[, dateColName := &quot;date NZ&quot;]
      } 
      if(nrow(select(tempDT, contains(&quot;UTC&quot;))) &gt; 0){ # requires dplyr
        setnames(tempDT, &#39;date UTC&#39;, &quot;dateTime_char&quot;)
        tempDT &lt;- tempDT[, dateColName := &quot;date UTC&quot;]
      }
      
      # Now use the pre-inferred dateFormat
      tempDT &lt;- tempDT[, dateFormat := filesToLoadDT[fullPath == f, dateFormat]]
      tempDT &lt;- tempDT[dateFormat %like% &quot;mdy&quot; &amp; dateColName %like% &quot;NZ&quot;, r_dateTime := mdy_hm(dateTime_char, tz = &quot;Pacific/Auckland&quot;)] # requires lubridate
      tempDT &lt;- tempDT[dateFormat %like% &quot;dmy&quot; &amp; dateColName %like% &quot;NZ&quot;, r_dateTime := dmy_hm(dateTime_char, tz = &quot;Pacific/Auckland&quot;)] # requires lubridate
      tempDT &lt;- tempDT[dateFormat %like% &quot;ydm&quot; &amp; dateColName %like% &quot;NZ&quot;, r_dateTime := ymd_hm(dateTime_char, tz = &quot;Pacific/Auckland&quot;)] # requires lubridate
      tempDT &lt;- tempDT[dateFormat %like% &quot;ymd&quot; &amp; dateColName %like% &quot;NZ&quot;, r_dateTime := ymd_hm(dateTime_char, tz = &quot;Pacific/Auckland&quot;)] # requires lubridate
      tempDT &lt;- tempDT[dateFormat %like% &quot;mdy&quot; &amp; dateColName %like% &quot;UTC&quot;, r_dateTime := mdy_hm(dateTime_char, tz = &quot;UTC&quot;)] # requires lubridate
      tempDT &lt;- tempDT[dateFormat %like% &quot;dmy&quot; &amp; dateColName %like% &quot;UTC&quot;, r_dateTime := dmy_hm(dateTime_char, tz = &quot;UTC&quot;)] # requires lubridate
      tempDT &lt;- tempDT[dateFormat %like% &quot;ydm&quot; &amp; dateColName %like% &quot;UTC&quot;, r_dateTime := ymd_hm(dateTime_char, tz = &quot;UTC&quot;)] # requires lubridate
      tempDT &lt;- tempDT[dateFormat %like% &quot;ymd&quot; &amp; dateColName %like% &quot;UTC&quot;, r_dateTime := ymd_hm(dateTime_char, tz = &quot;UTC&quot;)] # requires lubridate
      if(fullFb){
        print(head(tempDT))
        print(summary(tempDT))
        #print(table(tempDT$dateFormat))
        }
    
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, obsStartDate := min(as.Date(tempDT$r_dateTime))] # should be a sensible number and not NA
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, obsEndDate := max(as.Date(tempDT$r_dateTime))] # should be a sensible number and not NA
    fListCompleteDT &lt;- fListCompleteDT[fullPath == f, nCircuits := ncol(select(tempDT, contains(&quot;$&quot;)))] # check for the number of circuits - all seem to contain &quot;$&quot;
    tempHhDT &lt;- rbind(tempHhDT, tempDT, fill = TRUE) # just in case there are different numbers of columns (quite likely!)
  }
  
  # &gt; Remove duplicates caused by over-lapping files and dates etc ----
  # Need to remove all test vars for this
  try(tempHhDT$dateColName &lt;- NULL)
  try(tempHhDT$dateFormat &lt;- NULL)
  
  #nObs &lt;- nrow(tempHhDT)
  #print(paste0(&quot;N rows before removal of duplicates: &quot;, nObs))
  tempHhDT &lt;- unique(tempHhDT)
  #nObs &lt;- nrow(tempHhDT)
  #print(paste0(&quot;N rows after removal of duplicates: &quot;, nObs))
  
  hhStatTempDT &lt;- tempHhDT[, .(nObs = .N),keyby = (date = as.Date(r_dateTime))] # can&#39;t do sensible summary stats on W as some circuits are sub-sets of others!
  hhStatTempDT &lt;- hhStatTempDT[, hhID := hh]
  
  hhStatDT &lt;- rbind(hhStatDT,hhStatTempDT) # add to the collector
  
  # &gt; Save hh file ----
  ofile &lt;- paste0(outPath, &quot;1min/&quot;, hh,&quot;_all_1min_data.csv&quot;)
  write_csv(tempHhDT, ofile)
  print(paste0(&quot;Saved &quot;, ofile, &quot;, gzipping...&quot;))

  print(&quot;Col names: &quot;)
  print(names(tempHhDT))
  cmd &lt;- paste0(&quot;gzip -f &quot;, &quot;&#39;&quot;, path.expand(ofile), &quot;&#39;&quot;) # gzip it - use quotes in case of spaces in file name, expand path if needed
  try(system(cmd)) # in case it fails - if it does there will just be .csv files (not gzipped) - e.g. under windows
  print(paste0(&quot;Gzipped &quot;, ofile))
  tempHhDT &lt;- NULL # just in case
}</code></pre>
<pre><code>## [1] &quot;Loading: rf_01&quot;
## [1] &quot;Saved ~/Data/NZGreenGrid/gridspy/consolidated/1min/rf_01_all_1min_data.csv, gzipping...&quot;
## [1] &quot;Col names: &quot;
## [1] &quot;dateTime_char&quot;      &quot;Kitchen power$1632&quot; &quot;Heating$1633&quot;      
## [4] &quot;Mains$1634&quot;         &quot;Lights$1635&quot;        &quot;Hot water$1636&quot;    
## [7] &quot;Range$1637&quot;         &quot;r_dateTime&quot;        
## [1] &quot;Gzipped ~/Data/NZGreenGrid/gridspy/consolidated/1min/rf_01_all_1min_data.csv&quot;
## [1] &quot;Loading: rf_02&quot;
## [1] &quot;Saved ~/Data/NZGreenGrid/gridspy/consolidated/1min/rf_02_all_1min_data.csv, gzipping...&quot;
## [1] &quot;Col names: &quot;
## [1] &quot;dateTime_char&quot;               &quot;Fridge$1572&quot;                
## [3] &quot;Cooking Bath tile heat$1573&quot; &quot;Hot Water$1574&quot;             
## [5] &quot;Mains$1575&quot;                  &quot;Heating$1576&quot;               
## [7] &quot;Lights$1577&quot;                 &quot;r_dateTime&quot;                 
## [1] &quot;Gzipped ~/Data/NZGreenGrid/gridspy/consolidated/1min/rf_02_all_1min_data.csv&quot;
## [1] &quot;Loading: rf_25&quot;
## [1] &quot;Saved ~/Data/NZGreenGrid/gridspy/consolidated/1min/rf_25_all_1min_data.csv, gzipping...&quot;
## [1] &quot;Col names: &quot;
## [1] &quot;dateTime_char&quot;                  &quot;Heat Pump$2758&quot;                
## [3] &quot;Hob &amp; Kitchen Appliances$2759&quot;  &quot;Oven$2760&quot;                     
## [5] &quot;Hot Water - Controlled$2761&quot;    &quot;Incomer 2 - Uncontrolled $2762&quot;
## [7] &quot;Incomer 1 - Uncontrolled $2763&quot; &quot;r_dateTime&quot;                    
## [9] &quot;Incomer 1 - Uncontrolled$2757&quot; 
## [1] &quot;Gzipped ~/Data/NZGreenGrid/gridspy/consolidated/1min/rf_25_all_1min_data.csv&quot;
## [1] &quot;Loading: rf_46&quot;
## [1] &quot;Saved ~/Data/NZGreenGrid/gridspy/consolidated/1min/rf_46_all_1min_data.csv, gzipping...&quot;
## [1] &quot;Col names: &quot;
##  [1] &quot;dateTime_char&quot;                    
##  [2] &quot;Laundry &amp; Bedrooms$4228&quot;          
##  [3] &quot;Kitchen &amp; Bedrooms$4229&quot;          
##  [4] &quot;Incomer - Uncontrolled$4230&quot;      
##  [5] &quot;Hot Water - Controlled$4231&quot;      
##  [6] &quot;Heat Pumps (2x) &amp; Power$4232&quot;     
##  [7] &quot;Lighting$4233&quot;                    
##  [8] &quot;Heat Pumps (2x) &amp; Power$4399&quot;     
##  [9] &quot;Hot Water - Controlled$4400&quot;      
## [10] &quot;Incomer - Uncontrolled$4401&quot;      
## [11] &quot;Kitchen &amp; Bedrooms$4402&quot;          
## [12] &quot;Laundry &amp; Bedrooms$4403&quot;          
## [13] &quot;Lighting$4404&quot;                    
## [14] &quot;Incomer Voltage$4405&quot;             
## [15] &quot;r_dateTime&quot;                       
## [16] &quot;Laundry &amp; Bedrooms1$4228&quot;         
## [17] &quot;Kitchen &amp; Bedrooms1$4229&quot;         
## [18] &quot;Incomer - Uncontrolled1$4230&quot;     
## [19] &quot;Hot Water - Controlled1$4231&quot;     
## [20] &quot;Heat Pumps (2x) &amp; Power1$4232&quot;    
## [21] &quot;Lighting1$4233&quot;                   
## [22] &quot;Heat Pumps (2x) &amp; Power2$4399&quot;    
## [23] &quot;Hot Water - Controlled2$4400&quot;     
## [24] &quot;Incomer - Uncontrolled2$4401&quot;     
## [25] &quot;Kitchen &amp; Bedrooms2$4402&quot;         
## [26] &quot;Laundry &amp; Bedrooms2$4403&quot;         
## [27] &quot;Lighting2$4404&quot;                   
## [28] &quot;Heat Pumps (2x) &amp; Power_Imag$4399&quot;
## [29] &quot;Hot Water - Controlled_Imag$4400&quot; 
## [30] &quot;Incomer - Uncontrolled_Imag$4401&quot; 
## [31] &quot;Kitchen &amp; Bedrooms_Imag$4402&quot;     
## [32] &quot;Laundry &amp; Bedrooms_Imag$4403&quot;     
## [33] &quot;Lighting_Imag$4404&quot;               
## [1] &quot;Gzipped ~/Data/NZGreenGrid/gridspy/consolidated/1min/rf_46_all_1min_data.csv&quot;</code></pre>
<pre class="r"><code>#&gt; Save observed data stats for all files loaded ----
ofile &lt;- paste0(outPath, &quot;hhDailyObservationsStats.csv&quot;)
print(paste0(&quot;Saving daily observations stats by hhid to &quot;, ofile)) # write out version with file stats</code></pre>
<pre><code>## [1] &quot;Saving daily observations stats by hhid to ~/Data/NZGreenGrid/gridspy/consolidated/hhDailyObservationsStats.csv&quot;</code></pre>
<pre class="r"><code>write.csv(hhStatDT, ofile)
print(&quot;Done&quot;)</code></pre>
<pre><code>## [1] &quot;Done&quot;</code></pre>
</div>
<div id="data-quality-analysis" class="section level1">
<h1><span class="header-section-number">5</span> Data quality analysis</h1>
<p>Now produce some data quality plots &amp; tables.</p>
<p>The following plots show the number of observations per day per household. In theory we should not see:</p>
<ul>
<li>dates before 2014 or in to the future (they indicate data conversion errors)</li>
<li>more than 1440 observations per day (they indicate potentially duplicate data)</li>
</ul>
<pre class="r"><code># tile plot ----
ggplot(hhStatDT, aes( x = date, y = hhID, fill = nObs)) +
  geom_tile() +
  scale_fill_gradient(low = &quot;red&quot;, high = &quot;green&quot;) +
  scale_x_date(date_labels = &quot;%Y %b&quot;, date_breaks = &quot;6 months&quot;) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) + 
  labs(title = &quot;N observations per household per day for all loaded grid spy data&quot;,
       caption = paste0(myCaption,
                        &quot;\nOnly files of size &gt; &quot;, dataThreshold, &quot; bytes loaded&quot;)
       
  )</code></pre>
<p><img src="processNZGGElecCons1minData_files/figure-html/loadedFilesObsPlots-1.png" /><!-- --></p>
<pre class="r"><code>ggsave(paste0(outPath, &quot;gridSpyLoadedFileNobsTilePlot.png&quot;))</code></pre>
<pre><code>## Saving 7 x 5 in image</code></pre>
<pre class="r"><code># point plot ----
ggplot(hhStatDT, aes( x = date, y = nObs, colour = hhID)) +
  geom_point() +
  scale_x_date(date_labels = &quot;%Y %b&quot;, date_breaks = &quot;6 months&quot;) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) + 
  labs(title = &quot;N observations per household per day for all loaded grid spy data&quot;,
       caption = paste0(myCaption,
                        &quot;\nOnly files of size &gt; &quot;, dataThreshold, &quot; bytes loaded&quot;)
       
  )</code></pre>
<p><img src="processNZGGElecCons1minData_files/figure-html/loadedFilesObsPlots-2.png" /><!-- --></p>
<pre class="r"><code>ggsave(paste0(outPath, &quot;gridSpyLoadedFileNobsPointPlot.png&quot;))</code></pre>
<pre><code>## Saving 7 x 5 in image</code></pre>
<p>The following table shows the min/max observations per day and min/max dates for each household. As above, we should not see:</p>
<ul>
<li>dates before 2014 or in to the future (indicates date conversion errors)</li>
<li>more than 1440 observations per day (indicates potentially duplicate observations)</li>
</ul>
<p>We should also not see NA in any row (indicates date conversion errors).</p>
<p>If we do see any of these then we still have data cleaning work to do!</p>
<pre class="r"><code># Stats table (so we can pick out the dateTime errors)
t &lt;- hhStatDT[, .(minObs = min(nObs),
             maxObs = max(nObs), # should not be more than 1440, if so suggests duplicates
             minDate = min(date),
             maxDate = max(date)),
         keyby = .(hhID)]

kable(caption = &quot;Summary observation stats by hhID&quot;, t)</code></pre>
<table>
<caption>Summary observation stats by hhID</caption>
<thead>
<tr class="header">
<th align="left">hhID</th>
<th align="right">minObs</th>
<th align="right">maxObs</th>
<th align="left">minDate</th>
<th align="left">maxDate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">rf_01</td>
<td align="right">171</td>
<td align="right">1500</td>
<td align="left">2014-01-05</td>
<td align="left">2015-10-20</td>
</tr>
<tr class="even">
<td align="left">rf_02</td>
<td align="right">215</td>
<td align="right">1440</td>
<td align="left">2014-03-02</td>
<td align="left">2015-05-28</td>
</tr>
<tr class="odd">
<td align="left">rf_25</td>
<td align="right">45</td>
<td align="right">1500</td>
<td align="left">2015-05-24</td>
<td align="left">2016-10-22</td>
</tr>
<tr class="even">
<td align="left">rf_46</td>
<td align="right">305</td>
<td align="right">3000</td>
<td align="left">2015-03-26</td>
<td align="left">2018-02-19</td>
</tr>
</tbody>
</table>
</div>
<div id="runtime" class="section level1">
<h1><span class="header-section-number">6</span> Runtime</h1>
<pre class="r"><code>t &lt;- proc.time() - startTime

elapsed &lt;- t[[3]]</code></pre>
<p>Analysis completed in 461.618 seconds ( 7.69 minutes) using <a href="https://cran.r-project.org/package=knitr">knitr</a> in <a href="http://www.rstudio.com">RStudio</a> with R version 3.4.4 (2018-03-15) running on x86_64-apple-darwin15.6.0.</p>
</div>
<div id="r-environment" class="section level1">
<h1><span class="header-section-number">7</span> R environment</h1>
<p>R packages used:</p>
<ul>
<li>base R - for the basics <span class="citation">[@baseR]</span></li>
<li>data.table - for fast (big) data handling <span class="citation">[@data.table]</span></li>
<li>ggplot2 - for slick graphics <span class="citation">[@ggplot2]</span></li>
<li>dplyr - for select and contains <span class="citation">[@dplyr]</span></li>
<li>lubridate - date manipulation <span class="citation">[@lubridate]</span></li>
<li>knitr - to create this document <span class="citation">[@knitr]</span></li>
<li>greenGridr - for local NZ GREEN Grid utilities</li>
</ul>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.4.4 (2018-03-15)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.4
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] knitr_1.20          dplyr_0.7.4         readr_1.1.1        
## [4] ggplot2_2.2.1       lubridate_1.7.4     data.table_1.10.4-3
## [7] greenGridr_0.1.0   
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_0.12.16      bindr_0.1.1       magrittr_1.5     
##  [4] hms_0.4.2         munsell_0.4.3     colorspace_1.3-2 
##  [7] R6_2.2.2          rlang_0.2.0.9001  highr_0.6        
## [10] stringr_1.3.0     plyr_1.8.4        tools_3.4.4      
## [13] grid_3.4.4        gtable_0.2.0      htmltools_0.3.6  
## [16] assertthat_0.2.0  yaml_2.1.18       lazyeval_0.2.1   
## [19] rprojroot_1.3-2   digest_0.6.15     tibble_1.4.2     
## [22] bindrcpp_0.2.2    glue_1.2.0        evaluate_0.10.1  
## [25] rmarkdown_1.9     labeling_0.3      stringi_1.1.7    
## [28] compiler_3.4.4    pillar_1.2.2      scales_0.5.0.9000
## [31] backports_1.1.2   pkgconfig_2.0.1</code></pre>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
