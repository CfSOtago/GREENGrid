---
title: "Otago University Medical School Buildings Energy Consumption Data"
author: "Ben Anderson (b.anderson@soton.ac.uk, `@dataknut`)"
date: 'Last run at: `r Sys.time()`'
output:
  bookdown::html_document2:
    self_contained: no
    toc: yes
    toc_float: yes
bibliography: '`r path.expand("~/bibliography.bib")`'
---

# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Set start time ----
startTime <- proc.time()
library(data.table)
library(ggplot2)
library(kableExtra)
library(lubridate)
library(plotly)

```

# Load data

```{r loadData}

dt <- data.table::fread(path.expand("~/Data/OtagoUni/MedicalSchoolBuildings.csv"), 
                  )
message("N rows:", nrow(dt))
names(dt)
```

# Clean data
```{r cleanData}

dt[, dateTimeUTC := lubridate::dmy_hms(Time)] # is this UTC?
dt[, dateTimeNZ := lubridate::with_tz(dateTimeUTC, tzone = "Pacific/Auckland")] # assumes came in as UTC

dt[, hourUTC := lubridate::hour(dateTimeUTC)]
dt[, hourNZ := lubridate::hour(dateTimeNZ)]

# check
head(dt[, .(Time, dateTimeUTC, dateTimeNZ, hourUTC, hourNZ)])

```

```{r keepVars}
# keep the vars we want

cleanDT <- dt[, .(dateTimeUTC, dateTimeNZ, hourUTC, hourNZ,
                  avg = `Consumed Active Energy Total Tariff Sum L1-L3 (15m) [D20X Whole Medical School]-avg[Wh]`,
                  min = `Consumed Active Energy Total Tariff Sum L1-L3 (15m) [D20X Whole Medical School]-min[Wh]`,
                  max = `Consumed Active Energy Total Tariff Sum L1-L3 (15m) [D20X Whole Medical School]-max[Wh]`)]

s <- summary(cleanDT)

kableExtra::kable(s, caption = "Summary of data") %>%
  kable_styling()

ggplot2::ggplot(cleanDT, aes(x = dateTimeNZ)) +
  geom_line(aes(y = avg))
```

So clearly we have cumulative observations. Calculate the difference making sure the data us sorted by date time and repeat the plot.

```{r getEnergy, fig.cap="Average electricity consumption per 15 minute period" }
setkey(cleanDT, dateTimeNZ)
cleanDT[, avgCons := avg - shift(avg)]


p <- ggplot2::ggplot(cleanDT, aes(x = dateTimeNZ)) +
  geom_line(aes(y = avgCons))

p

plotly::ggplotly(p) # interactive version
```

Hmm, clearly some spikes where data has 'caught up'. We need to check where these data holes might be.


```{r plotMissing}
cleanDT[, dateNZ := lubridate::date(dateTimeNZ)]

plotDT <- cleanDT[, .(nObs = sum(.N)), keyby = .(dateNZ, hourNZ)]

ggplot2::ggplot(plotDT, aes(x = dateNZ, y = hourNZ, alpha = nObs)) + geom_tile()
#ggplot2::ggplot(plotDT, aes(x = date, y = hour, alpha = max)) + geom_tile()
```

Whats going on? Firstly:

 * 7 Apr 2019 - Daylight Saving Time Ended - this will effect observations around 02:00 on Sunday 7th April when there will be a whole hour 'catch up'. So 8 observations will be allocated to the DST break hour. This means that there will be a mini-spike in apparent consumption;
 * 18 Feb 2019 - most likely a data outage causes a 'catch-up' spike (see Figure \@ref(fig:getEnergy))


# Runtime


```{r check runtime, include=FALSE}
t <- proc.time() - startTime

elapsed <- t[[3]]
```

Analysis completed in `r round(elapsed,2)` seconds ( `r round(elapsed/60,2)` minutes) using [knitr](https://cran.r-project.org/package=knitr) in [RStudio](http://www.rstudio.com) with `r R.version.string` running on `r R.version$platform`.

# R environment

R packages used:

 * base R - for the basics [@baseR]
 * bookdown - to make the report [@bookdown]
 * data.table - for fast (big) data handling [@data.table]
 * lubridate - date manipulation [@lubridate]
 * ggplot2 - for slick graphics [@ggplot2]
 * kableExtra - neat tables [@kableExtra]
 * plotly - interactive plots [@plotly]

Session info:

```{r sessionInfo, echo=FALSE}
sessionInfo()
```

# References
