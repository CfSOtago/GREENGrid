---
title: "Otago University Medical School Buildings Energy Consumption Data"
author: "Ben Anderson (b.anderson@soton.ac.uk, `@dataknut`)"
date: 'Last run at: `r Sys.time()`'
output:
  bookdown::html_document2:
    self_contained: no
    toc: yes
    toc_float: yes
bibliography: '`r path.expand("~/bibliography.bib")`'
---

# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Set start time ----
startTime <- proc.time()
library(data.table)
library(ggplot2)
library(hms)
library(kableExtra)
library(lubridate)
library(plotly)

```

# Load data

```{r loadData}

dt <- data.table::fread(path.expand("~/Data/OtagoUni/MedicalSchoolBuildings.csv"), 
                  )
message("N rows:", nrow(dt))
names(dt)
```

# Clean data

During this process we force R to think the timezone of the original `Time` variable to be NZ Time.

```{r cleanData}

dt[, dateTime := lubridate::dmy_hms(Time)] # is this UTC? No we think it's NZ time
dt[, dateTime := lubridate::force_tz(dateTime, tzone = "Pacific/Auckland")]
dt[, hour := lubridate::hour(dateTime)]

# check
head(dt[, .(Time, dateTime, hour)])

```

```{r keepVars}
# keep the vars we want

cleanDT <- dt[, .(Time, dateTime, hour,
                  avg = `Consumed Active Energy Total Tariff Sum L1-L3 (15m) [D20X Whole Medical School]-avg[Wh]`,
                  min = `Consumed Active Energy Total Tariff Sum L1-L3 (15m) [D20X Whole Medical School]-min[Wh]`,
                  max = `Consumed Active Energy Total Tariff Sum L1-L3 (15m) [D20X Whole Medical School]-max[Wh]`)]

s <- summary(cleanDT)

kableExtra::kable(s, caption = "Summary of data") %>%
  kable_styling()

ggplot2::ggplot(cleanDT, aes(x = dateTime)) +
  geom_line(aes(y = avg))
```

So clearly we have cumulative observations. 

# Test data

Next we calculate the difference making sure the data us sorted by date time and repeat the plot.

```{r getEnergy, fig.cap="Average electricity consumption per 15 minute period" }
setkey(cleanDT, dateTime)
cleanDT[, avgCons := avg - shift(avg)]


p <- ggplot2::ggplot(cleanDT, aes(x = dateTime)) +
  geom_line(aes(y = avgCons))

p

plotly::ggplotly(p) # interactive version
```

Hmm, clearly some spikes where data has 'caught up'. We need to check where these data holes might be. The first set of plots summarise the data by date.


```{r byDate}
cleanDT[, date := lubridate::date(dateTime)]
plotDT <- cleanDT[, .(nObs = .N,
                      meanCons = mean(avgCons)), keyby = .(date)]
plotDT[, dow := lubridate::wday(date, label = TRUE)]

p <- ggplot2::ggplot(plotDT, aes(x = date, colour = dow)) + 
  geom_point(aes(y = nObs))
plotly::ggplotly(p)


p <- ggplot2::ggplot(plotDT, aes(x = date, colour = dow)) + 
  geom_point(aes(y = meanCons))
plotly::ggplotly(p)

```

Next we look by date and hour of the day.

```{r byDateHour}
plotDT <- cleanDT[, .(nObs = .N,
                      meanCons = mean(avgCons)), keyby = .(date, hour)]

ggplot2::ggplot(plotDT, aes(x = date, y = hour, alpha = nObs)) + geom_tile()

ggplot2::ggplot(plotDT, aes(x = date, y = hour, alpha = meanCons)) + geom_tile()


```

Whats going on? Firstly:

 * 7 Apr 2019 - Daylight Saving Time Ended - this will effect observations around 02:00 on Sunday 7th April when there will be a whole hour 'catch up'. So 8 observations will be allocated to the DST break hour. This means that there will be a mini-spike in apparent consumption;
 * 18 Feb 2019 - most likely a data outage causes a 'catch-up' spike (see Figure \@ref(fig:getEnergy))

# Demand profile plots

No data cleaning here. Should remove the 18th Feb data point...

```{r profilePlots, fig.height=8, fig.cap="Monthly consumption profile plots"}
cleanDT[, hms := hms::as.hms(dateTime)]
cleanDT[, dow := lubridate::wday(date, label = TRUE)]
cleanDT[, month := lubridate::month(date, label = TRUE)]

plotDT <- cleanDT[, .(nObs = .N,
                      meanCons = mean(avgCons)), keyby = .(hms, dow, month)]

ggplot2::ggplot(plotDT, aes(x = hms, y = meanCons, colour = dow)) + 
  geom_point() +
  facet_grid(month ~ .)

```
# Runtime


```{r check runtime, include=FALSE}
t <- proc.time() - startTime

elapsed <- t[[3]]
```

Analysis completed in `r round(elapsed,2)` seconds ( `r round(elapsed/60,2)` minutes) using [knitr](https://cran.r-project.org/package=knitr) in [RStudio](http://www.rstudio.com) with `r R.version.string` running on `r R.version$platform`.

# R environment

R packages used:

 * base R - for the basics [@baseR]
 * bookdown - to make the report [@bookdown]
 * data.table - for fast (big) data handling [@data.table]
 * lubridate - date manipulation [@lubridate]
 * ggplot2 - for slick graphics [@ggplot2]
 * kableExtra - neat tables [@kableExtra]
 * plotly - interactive plots [@plotly]

Session info:

```{r sessionInfo, echo=FALSE}
sessionInfo()
```

# References
